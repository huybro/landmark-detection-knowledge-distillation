{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02bf3019",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-30T23:50:20.072387Z",
     "iopub.status.busy": "2024-11-30T23:50:20.072119Z",
     "iopub.status.idle": "2024-11-30T23:50:33.306452Z",
     "shell.execute_reply": "2024-11-30T23:50:33.305462Z"
    },
    "papermill": {
     "duration": 13.244219,
     "end_time": "2024-11-30T23:50:33.308502",
     "exception": false,
     "start_time": "2024-11-30T23:50:20.064283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\r\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-x6wpo_7y\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-x6wpo_7y\r\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting ftfy (from clip==1.0)\r\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (21.3)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2024.5.15)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.4)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.4.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.19.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->clip==1.0) (3.1.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (2024.6.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\r\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: clip\r\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=30e1122192af2714ac8603fc7dce1d81ad6dcad3f9ace025119f74c77f4fb2ea\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0xayjltx/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\r\n",
      "Successfully built clip\r\n",
      "Installing collected packages: ftfy, clip\r\n",
      "Successfully installed clip-1.0 ftfy-6.3.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b27e9f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:50:33.325615Z",
     "iopub.status.busy": "2024-11-30T23:50:33.325241Z",
     "iopub.status.idle": "2024-11-30T23:50:43.078296Z",
     "shell.execute_reply": "2024-11-30T23:50:43.077355Z"
    },
    "papermill": {
     "duration": 9.762914,
     "end_time": "2024-11-30T23:50:43.080036",
     "exception": false,
     "start_time": "2024-11-30T23:50:33.317122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.4.17)\r\n",
      "Collecting albumentations\r\n",
      "  Downloading albumentations-1.4.21-py3-none-any.whl.metadata (31 kB)\r\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.14.1)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.2)\r\n",
      "Requirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (2.9.2)\r\n",
      "Collecting albucore==0.0.20 (from albumentations)\r\n",
      "  Downloading albucore-0.0.20-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.2.0)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.10.0.84)\r\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.20->albumentations)\r\n",
      "  Downloading stringzilla-3.10.11-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting simsimd>=5.9.2 (from albucore==0.0.20->albumentations)\r\n",
      "  Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (66 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\r\n",
      "Downloading albumentations-1.4.21-py3-none-any.whl (227 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.9/227.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading albucore-0.0.20-py3-none-any.whl (12 kB)\r\n",
      "Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (632 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.7/632.7 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading stringzilla-3.10.11-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (291 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.7/291.7 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: stringzilla, simsimd, albucore, albumentations\r\n",
      "  Attempting uninstall: albucore\r\n",
      "    Found existing installation: albucore 0.0.17\r\n",
      "    Uninstalling albucore-0.0.17:\r\n",
      "      Successfully uninstalled albucore-0.0.17\r\n",
      "  Attempting uninstall: albumentations\r\n",
      "    Found existing installation: albumentations 1.4.17\r\n",
      "    Uninstalling albumentations-1.4.17:\r\n",
      "      Successfully uninstalled albumentations-1.4.17\r\n",
      "Successfully installed albucore-0.0.20 albumentations-1.4.21 simsimd-6.2.1 stringzilla-3.10.11\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f8789",
   "metadata": {
    "papermill": {
     "duration": 0.007254,
     "end_time": "2024-11-30T23:50:43.095118",
     "exception": false,
     "start_time": "2024-11-30T23:50:43.087864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e66b394e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:50:43.111217Z",
     "iopub.status.busy": "2024-11-30T23:50:43.110921Z",
     "iopub.status.idle": "2024-11-30T23:50:52.697638Z",
     "shell.execute_reply": "2024-11-30T23:50:52.696952Z"
    },
    "papermill": {
     "duration": 9.597053,
     "end_time": "2024-11-30T23:50:52.699595",
     "exception": false,
     "start_time": "2024-11-30T23:50:43.102542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gc\n",
    "\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "\n",
    "import math, random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "\n",
    "import timm\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import clip\n",
    "\n",
    "\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import wandb\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b47213e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:50:52.716480Z",
     "iopub.status.busy": "2024-11-30T23:50:52.716057Z",
     "iopub.status.idle": "2024-11-30T23:50:52.722967Z",
     "shell.execute_reply": "2024-11-30T23:50:52.722167Z"
    },
    "papermill": {
     "duration": 0.017083,
     "end_time": "2024-11-30T23:50:52.724579",
     "exception": false,
     "start_time": "2024-11-30T23:50:52.707496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "N_WORKERS = os.cpu_count() \n",
    "\n",
    "USE_AMP = False # can change True if using T4 or newer than Ampere\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "CLIP_MODEL_NAME = \"RN101\"\n",
    "\n",
    "IMG_SIZE = [224, 224]\n",
    "\n",
    "AUG_PROB = 0.2\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "if DEBUG:\n",
    "\n",
    "    EPOCHS = 3\n",
    "\n",
    "GRAD_ACC = 1\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "MAX_GRAD_NORM = None\n",
    "\n",
    "EARLY_STOPPING_EPOCH = 3\n",
    "\n",
    "OUTPUT_DIR = f'clip_landmark_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e68c25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:50:52.740707Z",
     "iopub.status.busy": "2024-11-30T23:50:52.740112Z",
     "iopub.status.idle": "2024-11-30T23:50:52.743563Z",
     "shell.execute_reply": "2024-11-30T23:50:52.742981Z"
    },
    "papermill": {
     "duration": 0.013097,
     "end_time": "2024-11-30T23:50:52.745131",
     "exception": false,
     "start_time": "2024-11-30T23:50:52.732034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e418ca0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:50:52.760879Z",
     "iopub.status.busy": "2024-11-30T23:50:52.760613Z",
     "iopub.status.idle": "2024-11-30T23:50:53.805538Z",
     "shell.execute_reply": "2024-11-30T23:50:53.804698Z"
    },
    "papermill": {
     "duration": 1.054916,
     "end_time": "2024-11-30T23:50:53.807466",
     "exception": false,
     "start_time": "2024-11-30T23:50:52.752550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>category</th>\n",
       "      <th>supercategory</th>\n",
       "      <th>hierarchical_label</th>\n",
       "      <th>natural_or_human_made</th>\n",
       "      <th>cleaned_supercategory</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>image_path</th>\n",
       "      <th>landmark_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87a5dfadcaeba144</td>\n",
       "      <td>93036</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Nav...</td>\n",
       "      <td>naval base</td>\n",
       "      <td>harbor</td>\n",
       "      <td>human-made</td>\n",
       "      <td>naval base</td>\n",
       "      <td>Guantánamo Province , Cuba</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p3...</td>\n",
       "      <td>Naval Station Guantanamo Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53824bfa2b3e569c</td>\n",
       "      <td>93036</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Nav...</td>\n",
       "      <td>naval base</td>\n",
       "      <td>harbor</td>\n",
       "      <td>human-made</td>\n",
       "      <td>naval base</td>\n",
       "      <td>Guantánamo Province , Cuba</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p2...</td>\n",
       "      <td>Naval Station Guantanamo Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>080a99cff9666667</td>\n",
       "      <td>93036</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Nav...</td>\n",
       "      <td>naval base</td>\n",
       "      <td>harbor</td>\n",
       "      <td>human-made</td>\n",
       "      <td>naval base</td>\n",
       "      <td>Guantánamo Province , Cuba</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p1...</td>\n",
       "      <td>Naval Station Guantanamo Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b86710311289fa90</td>\n",
       "      <td>93036</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Nav...</td>\n",
       "      <td>naval base</td>\n",
       "      <td>harbor</td>\n",
       "      <td>human-made</td>\n",
       "      <td>naval base</td>\n",
       "      <td>Guantánamo Province , Cuba</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p4...</td>\n",
       "      <td>Naval Station Guantanamo Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5554c986662c2587</td>\n",
       "      <td>93036</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Nav...</td>\n",
       "      <td>naval base</td>\n",
       "      <td>harbor</td>\n",
       "      <td>human-made</td>\n",
       "      <td>naval base</td>\n",
       "      <td>Guantánamo Province , Cuba</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p2...</td>\n",
       "      <td>Naval Station Guantanamo Bay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  landmark_id  \\\n",
       "0  87a5dfadcaeba144        93036   \n",
       "1  53824bfa2b3e569c        93036   \n",
       "2  080a99cff9666667        93036   \n",
       "3  b86710311289fa90        93036   \n",
       "4  5554c986662c2587        93036   \n",
       "\n",
       "                                            category supercategory  \\\n",
       "0  http://commons.wikimedia.org/wiki/Category:Nav...    naval base   \n",
       "1  http://commons.wikimedia.org/wiki/Category:Nav...    naval base   \n",
       "2  http://commons.wikimedia.org/wiki/Category:Nav...    naval base   \n",
       "3  http://commons.wikimedia.org/wiki/Category:Nav...    naval base   \n",
       "4  http://commons.wikimedia.org/wiki/Category:Nav...    naval base   \n",
       "\n",
       "  hierarchical_label natural_or_human_made cleaned_supercategory  \\\n",
       "0             harbor            human-made            naval base   \n",
       "1             harbor            human-made            naval base   \n",
       "2             harbor            human-made            naval base   \n",
       "3             harbor            human-made            naval base   \n",
       "4             harbor            human-made            naval base   \n",
       "\n",
       "                     location country  \\\n",
       "0  Guantánamo Province , Cuba    Cuba   \n",
       "1  Guantánamo Province , Cuba    Cuba   \n",
       "2  Guantánamo Province , Cuba    Cuba   \n",
       "3  Guantánamo Province , Cuba    Cuba   \n",
       "4  Guantánamo Province , Cuba    Cuba   \n",
       "\n",
       "                                          image_path  \\\n",
       "0  /kaggle/input/google-landmarks-v2-index-set-p3...   \n",
       "1  /kaggle/input/google-landmarks-v2-index-set-p2...   \n",
       "2  /kaggle/input/google-landmarks-v2-index-set-p1...   \n",
       "3  /kaggle/input/google-landmarks-v2-index-set-p4...   \n",
       "4  /kaggle/input/google-landmarks-v2-index-set-p2...   \n",
       "\n",
       "                  landmark_name  \n",
       "0  Naval Station Guantanamo Bay  \n",
       "1  Naval Station Guantanamo Bay  \n",
       "2  Naval Station Guantanamo Bay  \n",
       "3  Naval Station Guantanamo Bay  \n",
       "4  Naval Station Guantanamo Bay  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/google-landmarks-v2-index-subset-metadata/cleaned_landmark_index_subset_150k_with_locations_v4.csv\")\n",
    "\n",
    "if DEBUG:\n",
    "\n",
    "    # Reduce to 1000 samples for quick debugging\n",
    "\n",
    "    train_df = train_df.sample(1000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a12df2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:50:53.824742Z",
     "iopub.status.busy": "2024-11-30T23:50:53.824006Z",
     "iopub.status.idle": "2024-11-30T23:50:53.847971Z",
     "shell.execute_reply": "2024-11-30T23:50:53.847153Z"
    },
    "papermill": {
     "duration": 0.034149,
     "end_time": "2024-11-30T23:50:53.849675",
     "exception": false,
     "start_time": "2024-11-30T23:50:53.815526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_CLASSES = train_df.landmark_name.nunique()\n",
    "\n",
    "class_names = train_df.landmark_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "090bca4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:50:53.866492Z",
     "iopub.status.busy": "2024-11-30T23:50:53.866014Z",
     "iopub.status.idle": "2024-11-30T23:51:05.184140Z",
     "shell.execute_reply": "2024-11-30T23:51:05.183183Z"
    },
    "papermill": {
     "duration": 11.329455,
     "end_time": "2024-11-30T23:51:05.186919",
     "exception": false,
     "start_time": "2024-11-30T23:50:53.857464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 278M/278M [00:03<00:00, 75.7MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load CLIP model\n",
    "\n",
    "embedding_device = device\n",
    "\n",
    "model, _ = clip.load(CLIP_MODEL_NAME, device=embedding_device)\n",
    "\n",
    "\n",
    "\n",
    "# Define class names and tokenize\n",
    "\n",
    "text_prompts = [f\"A photo of {name} or its part\" for name in class_names]\n",
    "\n",
    "text_tokens = clip.tokenize(text_prompts).to(embedding_device)\n",
    "\n",
    "\n",
    "\n",
    "# Compute text embeddings\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    text_embeddings = model.encode_text(text_tokens)\n",
    "\n",
    "text_embeddings = text_embeddings / text_embeddings.norm(dim=-1, keepdim=True)  # Normalize for cosine similarity\n",
    "\n",
    "text_embeddings = text_embeddings.float()\n",
    "torch.save(text_embeddings,'text_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e259db4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.210003Z",
     "iopub.status.busy": "2024-11-30T23:51:05.209718Z",
     "iopub.status.idle": "2024-11-30T23:51:05.215151Z",
     "shell.execute_reply": "2024-11-30T23:51:05.214272Z"
    },
    "papermill": {
     "duration": 0.019685,
     "end_time": "2024-11-30T23:51:05.216741",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.197056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text_embeddings = torch.load(\"/kaggle/input/text_embeddings/pytorch/default/1/text_embeddings.pt\", weights_only=True)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"text_embeddings = torch.load(\"/kaggle/input/text_embeddings/pytorch/default/1/text_embeddings.pt\", weights_only=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5219974",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.240360Z",
     "iopub.status.busy": "2024-11-30T23:51:05.239812Z",
     "iopub.status.idle": "2024-11-30T23:51:05.245964Z",
     "shell.execute_reply": "2024-11-30T23:51:05.245141Z"
    },
    "papermill": {
     "duration": 0.021743,
     "end_time": "2024-11-30T23:51:05.247962",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.226219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_name_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "idx_to_class_name = {idx: class_name for class_name, idx in class_name_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10e2773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.285369Z",
     "iopub.status.busy": "2024-11-30T23:51:05.284717Z",
     "iopub.status.idle": "2024-11-30T23:51:05.312615Z",
     "shell.execute_reply": "2024-11-30T23:51:05.311249Z"
    },
    "papermill": {
     "duration": 0.049272,
     "end_time": "2024-11-30T23:51:05.315588",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.266316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "transforms_train = A.Compose([\n",
    "\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=AUG_PROB),\n",
    "\n",
    "    A.OneOf([\n",
    "\n",
    "        A.MotionBlur(blur_limit=5),\n",
    "\n",
    "        A.MedianBlur(blur_limit=5),\n",
    "\n",
    "        A.GaussianBlur(blur_limit=5),\n",
    "\n",
    "        A.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "\n",
    "    ], p=AUG_PROB),\n",
    "\n",
    "\n",
    "\n",
    "    A.OneOf([\n",
    "\n",
    "        A.OpticalDistortion(distort_limit=1.0),\n",
    "\n",
    "        A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "\n",
    "        A.ElasticTransform(alpha=3),\n",
    "\n",
    "    ], p=AUG_PROB),\n",
    "\n",
    "\n",
    "\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=AUG_PROB),\n",
    "\n",
    "    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "\n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=1, min_height=8, min_width=8, p=AUG_PROB),    \n",
    "\n",
    "    A.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], \n",
    "\n",
    "                         std=[0.26862954, 0.26130258, 0.27577711])\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "transforms_val = A.Compose([\n",
    "\n",
    "    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "\n",
    "    A.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], \n",
    "\n",
    "                         std=[0.26862954, 0.26130258, 0.27577711])\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db038abd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.350771Z",
     "iopub.status.busy": "2024-11-30T23:51:05.349931Z",
     "iopub.status.idle": "2024-11-30T23:51:05.357441Z",
     "shell.execute_reply": "2024-11-30T23:51:05.356773Z"
    },
    "papermill": {
     "duration": 0.030917,
     "end_time": "2024-11-30T23:51:05.359538",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.328621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GoogleLandmarksDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, class_name_to_idx, transform=None):\n",
    "\n",
    "        self.df = df\n",
    "\n",
    "        self.class_name_to_idx = class_name_to_idx  # Maps class name to index\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        t = self.df.iloc[idx]\n",
    "\n",
    "        class_name = t['landmark_name']\n",
    "\n",
    "        class_name_idx = self.class_name_to_idx[class_name]\n",
    "\n",
    "        \n",
    "\n",
    "        p = f'{t[\"image_path\"]}'\n",
    "\n",
    "        img = Image.open(p)\n",
    "\n",
    "        img = np.array(img)\n",
    "\n",
    "            \n",
    "\n",
    "        # Apply transformations if provided\n",
    "\n",
    "        if self.transform:\n",
    "\n",
    "            img = self.transform(image=np.array(img))['image']\n",
    "\n",
    "        \n",
    "\n",
    "        # Convert image to tensor if needed\n",
    "\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "\n",
    "        \n",
    "\n",
    "        return img, class_name_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c07eca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.385102Z",
     "iopub.status.busy": "2024-11-30T23:51:05.384858Z",
     "iopub.status.idle": "2024-11-30T23:51:05.398578Z",
     "shell.execute_reply": "2024-11-30T23:51:05.397849Z"
    },
    "papermill": {
     "duration": 0.029227,
     "end_time": "2024-11-30T23:51:05.400803",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.371576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CrossModalDistillationModel(nn.Module):\n",
    "    def __init__(self, teacher_model, student_model, text_embeddings, projection_dim=512):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher_model\n",
    "        self.student = student_model\n",
    "        self.text_embeddings = text_embeddings\n",
    "        \n",
    "        # Freeze teacher\n",
    "        for param in self.teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Get student features dimension\n",
    "        in_features = student_model.get_classifier().in_features\n",
    "        num_classes = student_model.get_classifier().out_features\n",
    "        \n",
    "        # Improved projection head with residual connections\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.LayerNorm(1024),  # Layer norm instead of batch norm\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(1024, projection_dim)\n",
    "        )\n",
    "        \n",
    "        # Improved classifier with bottleneck\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Temperature parameter with better initialization\n",
    "        self.temperature = nn.Parameter(torch.log(torch.ones([]) / 0.07))\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"\n",
    "        Proper weight initialization for better training\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LayerNorm):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, images, return_features=True):\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        # Teacher forward pass with gradient checkpointing for memory efficiency\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            teacher_logits, teacher_features = self.teacher(images)\n",
    "            \n",
    "        # Student forward pass\n",
    "        student_features = self.student.forward_features(images)\n",
    "        \n",
    "        # Global average pooling with better numerical stability\n",
    "        student_features = F.adaptive_avg_pool2d(student_features, (1, 1))\n",
    "        student_features = student_features.view(batch_size, -1)\n",
    "        \n",
    "        # Project student features\n",
    "        student_projected = self.projection_head(student_features)\n",
    "        student_projected = F.normalize(student_projected, dim=-1)\n",
    "        \n",
    "        # Compute classification logits\n",
    "        student_logits = self.classifier(student_features)\n",
    "        \n",
    "        if return_features:\n",
    "            return {\n",
    "                'teacher_logits': teacher_logits,\n",
    "                'student_logits': student_logits,\n",
    "                'teacher_features': teacher_features,\n",
    "                'student_projected': student_projected,\n",
    "                'student_features': student_features,\n",
    "                'temperature': self.temperature.exp()  # Useful for monitoring\n",
    "            }\n",
    "        return student_logits\n",
    "    \n",
    "    def get_last_selfattention(self, x):\n",
    "        \"\"\"\n",
    "        Get attention maps for visualization\n",
    "        \"\"\"\n",
    "        return self.student.get_last_selfattention(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ce213fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.424849Z",
     "iopub.status.busy": "2024-11-30T23:51:05.424463Z",
     "iopub.status.idle": "2024-11-30T23:51:05.431314Z",
     "shell.execute_reply": "2024-11-30T23:51:05.430809Z"
    },
    "papermill": {
     "duration": 0.021216,
     "end_time": "2024-11-30T23:51:05.433106",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.411890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GoogleLandmarksModel(nn.Module):\n",
    "    def __init__(self, text_embeddings, model_name=CLIP_MODEL_NAME, device=device):\n",
    "        super(GoogleLandmarksModel, self).__init__()\n",
    "        # Load the CLIP model\n",
    "        self.model, _ = clip.load(model_name, device=device)\n",
    "        \n",
    "        # Store the precomputed text embeddings\n",
    "        self.text_embeddings = text_embeddings\n",
    "        self.text_embeddings.requires_grad = False\n",
    "        \n",
    "        # Freeze the text encoder to save memory and computation\n",
    "        for param in self.model.transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, images):\n",
    "        # Compute image embeddings\n",
    "        image_embeddings = self.model.encode_image(images)\n",
    "        \n",
    "        # Normalize image embeddings without in-place operation\n",
    "        image_embeddings = image_embeddings / image_embeddings.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Check and match data types for mixed precision\n",
    "        if image_embeddings.dtype != self.text_embeddings.dtype:\n",
    "            text_embeddings = self.text_embeddings.to(image_embeddings.dtype)\n",
    "        else:\n",
    "            text_embeddings = self.text_embeddings\n",
    "        \n",
    "        # Compute cosine similarity with text embeddings\n",
    "        similarity = image_embeddings @ self.text_embeddings.T\n",
    "        return similarity, image_embeddings  # Similarity scores for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9880323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.458002Z",
     "iopub.status.busy": "2024-11-30T23:51:05.457758Z",
     "iopub.status.idle": "2024-11-30T23:51:05.462477Z",
     "shell.execute_reply": "2024-11-30T23:51:05.461769Z"
    },
    "papermill": {
     "duration": 0.020143,
     "end_time": "2024-11-30T23:51:05.465293",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.445150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.alpha = 0.4\n",
    "\n",
    "        self.beta = 0.2\n",
    "\n",
    "        self.gamma = 0.4\n",
    "\n",
    "        self.temperature = 2.0\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.batch_size = BATCH_SIZE\n",
    "\n",
    "        self.n_workers = N_WORKERS\n",
    "\n",
    "        self.max_grad_norm = MAX_GRAD_NORM\n",
    "\n",
    "        self.log_interval = 100\n",
    "\n",
    "        self.use_amp = False\n",
    "\n",
    "        self.use_wandb = False  # Set to True if using wandb\n",
    "\n",
    "        self.warmup_steps = 100\n",
    "\n",
    "        self.gradient_accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7bd3650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.521059Z",
     "iopub.status.busy": "2024-11-30T23:51:05.520837Z",
     "iopub.status.idle": "2024-11-30T23:51:05.529039Z",
     "shell.execute_reply": "2024-11-30T23:51:05.528161Z"
    },
    "papermill": {
     "duration": 0.038191,
     "end_time": "2024-11-30T23:51:05.531213",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.493022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NKDLoss:\n",
    "    def __init__(self, alpha=1.0, lambda_temp=1.0):\n",
    "        \"\"\"\n",
    "        Initializes NKD Loss.\n",
    "        Args:\n",
    "            alpha: Hyperparameter for scaling Ldistributed.\n",
    "            lambda_temp: Temperature for knowledge distillation.\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.lambda_temp = lambda_temp\n",
    "\n",
    "    def __call__(self, student_logits, teacher_logits, targets):\n",
    "        \"\"\"\n",
    "        Compute NKD Loss.\n",
    "        Args:\n",
    "            student_logits: Logits from the student model. Shape: (batch_size, num_classes)\n",
    "            teacher_logits: Logits from the teacher model. Shape: (batch_size, num_classes)\n",
    "            targets: Ground-truth labels. Shape: (batch_size,)\n",
    "        Returns:\n",
    "            Total NKD loss (scalar).\n",
    "        \"\"\"\n",
    "        # Apply temperature scaling\n",
    "        student_probs = F.softmax(student_logits / self.lambda_temp, dim=-1)\n",
    "        teacher_probs = F.softmax(teacher_logits / self.lambda_temp, dim=-1)\n",
    "        \n",
    "        # Ground-truth one-hot labels\n",
    "        target_probs = F.one_hot(targets, num_classes=student_logits.size(1)).float()\n",
    "        \n",
    "        # Extract probabilities for the target class\n",
    "        student_target_probs = student_probs.gather(1, targets.view(-1, 1)).squeeze(1)\n",
    "        teacher_target_probs = teacher_probs.gather(1, targets.view(-1, 1)).squeeze(1)\n",
    "        \n",
    "        # Compute Lori: Original loss\n",
    "        lori = -torch.log(student_target_probs + 1e-8).mean()\n",
    "        \n",
    "        # Compute Lsoft: Soft loss\n",
    "        lsoft = -(teacher_target_probs * torch.log(student_target_probs + 1e-8)).mean()\n",
    "        \n",
    "        # Compute Ldistributed: Distributed loss\n",
    "        # Exclude target class for teacher and student\n",
    "        non_target_teacher_probs = teacher_probs * (1 - target_probs)\n",
    "        non_target_student_probs = student_probs * (1 - target_probs)\n",
    "        \n",
    "        # Normalize non-target probabilities\n",
    "        normalized_teacher_probs = non_target_teacher_probs / (1 - teacher_target_probs.unsqueeze(1) + 1e-8)\n",
    "        normalized_student_probs = non_target_student_probs / (1 - student_target_probs.unsqueeze(1) + 1e-8)\n",
    "        \n",
    "        # Distributed loss\n",
    "        ldistributed = -(normalized_teacher_probs * torch.log(normalized_student_probs + 1e-8)).sum(dim=1).mean()\n",
    "        ldistributed *= self.alpha * (self.lambda_temp ** 2)\n",
    "        \n",
    "        # Total loss\n",
    "        lnkd = lori + lsoft + ldistributed\n",
    "        return lnkd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b1b88d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.560871Z",
     "iopub.status.busy": "2024-11-30T23:51:05.560610Z",
     "iopub.status.idle": "2024-11-30T23:51:05.571551Z",
     "shell.execute_reply": "2024-11-30T23:51:05.570903Z"
    },
    "papermill": {
     "duration": 0.031245,
     "end_time": "2024-11-30T23:51:05.573177",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.541932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EnhancedDistillationLoss(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.alpha = config.alpha  # KD loss weight\n",
    "        self.beta = config.beta    # Feature alignment weight\n",
    "        self.gamma = config.gamma  # CE loss weight\n",
    "        self.temperature = config.temperature\n",
    "        self.contrastive_weight = 0.1\n",
    "        \n",
    "    def contrastive_loss(self, features, labels):\n",
    "        \"\"\"\n",
    "        Improved contrastive loss with better numerical stability\n",
    "        \"\"\"\n",
    "        # Normalize features for better stability\n",
    "        features = F.normalize(features, dim=1)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity = torch.matmul(features, features.t())\n",
    "        \n",
    "        # Create label mask for positive pairs\n",
    "        labels = labels.view(-1, 1)\n",
    "        mask = (labels == labels.T).float()\n",
    "        \n",
    "        # Remove diagonal from mask (self-pairs)\n",
    "        mask = mask.fill_diagonal_(0)\n",
    "        \n",
    "        # Temperature-scaled similarities with numerical stability\n",
    "        similarity = similarity / self.temperature\n",
    "        \n",
    "        # Stable version of exp(similarity)\n",
    "        sim_exp = torch.exp(similarity - similarity.max(dim=1, keepdim=True)[0])\n",
    "        \n",
    "        # Compute positive and negative pairs\n",
    "        pos_sim = sim_exp * mask\n",
    "        neg_sim = sim_exp * (1 - mask)\n",
    "        \n",
    "        # Add small epsilon to prevent log(0)\n",
    "        eps = 1e-8\n",
    "        loss = -torch.log(\n",
    "            (pos_sim.sum(1) + eps) / (pos_sim.sum(1) + neg_sim.sum(1) + eps)\n",
    "        ).mean()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def feature_alignment_loss(self, student_features, teacher_features):\n",
    "        \"\"\"\n",
    "        Improved feature alignment using cosine similarity\n",
    "        \"\"\"\n",
    "        student_features = F.normalize(student_features, dim=1)\n",
    "        teacher_features = F.normalize(teacher_features, dim=1)\n",
    "        return 1 - (student_features * teacher_features).sum(dim=1).mean()\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        # Convert all inputs to float and ensure contiguous memory\n",
    "        teacher_logits = outputs['teacher_logits'].float().contiguous()\n",
    "        student_logits = outputs['student_logits'].float().contiguous()\n",
    "        teacher_features = outputs['teacher_features'].float().contiguous()\n",
    "        student_projected = outputs['student_projected'].float().contiguous()\n",
    "        \n",
    "        # 1. Knowledge Distillation Loss with stability\n",
    "        nkd_loss_fn = NKDLoss(alpha=self.alpha, lambda_temp=1.0)\n",
    "        kd_loss = nkd_loss_fn(student_logits, teacher_logits, labels)\n",
    "\n",
    "        # 2. Improved Feature Alignment Loss\n",
    "        feature_loss = self.feature_alignment_loss(student_projected, teacher_features)\n",
    "        \n",
    "        # 3. Cross Entropy Loss with label smoothing\n",
    "        ce_loss = F.cross_entropy(student_logits, labels, label_smoothing=0.1)\n",
    "        \n",
    "        # 4. Improved Contrastive Loss\n",
    "        cont_loss = self.contrastive_loss(student_projected, labels)\n",
    "        \n",
    "        # 5. Teacher Loss (for monitoring only)\n",
    "        teacher_loss = F.cross_entropy(teacher_logits, labels)\n",
    "        \n",
    "        # Weighted sum of losses\n",
    "        total_loss = (\n",
    "            self.alpha * kd_loss +\n",
    "            self.beta * feature_loss +\n",
    "            self.gamma * ce_loss +\n",
    "            self.contrastive_weight * cont_loss\n",
    "        )\n",
    "        \n",
    "        return total_loss, {\n",
    "            'kd_loss': kd_loss.item(),\n",
    "            'feature_loss': feature_loss.item(),\n",
    "            'ce_loss': ce_loss.item(),\n",
    "            'cont_loss': cont_loss.item(),\n",
    "            'teacher_loss': teacher_loss.item(),\n",
    "            'total_loss': total_loss.item()\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def update_temperature(self, epoch, max_epochs):\n",
    "        \"\"\"\n",
    "        Temperature annealing\n",
    "        \"\"\"\n",
    "        self.temperature = max(0.07, 1.0 - (epoch / max_epochs) * 0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e71fafa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.592800Z",
     "iopub.status.busy": "2024-11-30T23:51:05.592510Z",
     "iopub.status.idle": "2024-11-30T23:51:05.601289Z",
     "shell.execute_reply": "2024-11-30T23:51:05.600532Z"
    },
    "papermill": {
     "duration": 0.020427,
     "end_time": "2024-11-30T23:51:05.602919",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.582492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, config, scheduler=None):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    metrics = defaultdict(float)  # Tracks additional metrics\n",
    "\n",
    "    scaler = GradScaler() if config.use_amp else None\n",
    "\n",
    "    \n",
    "\n",
    "    pbar = tqdm(train_loader, desc='Training', leave =True)\n",
    "\n",
    "    \n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "\n",
    "        images, labels = images.to(config.device), labels.to(config.device)\n",
    "\n",
    "        \n",
    "\n",
    "        # Mixed precision training\n",
    "\n",
    "        if config.use_amp:\n",
    "\n",
    "            with autocast():\n",
    "\n",
    "                outputs = model(images, return_features=True)\n",
    "\n",
    "                loss, batch_metrics = criterion(outputs, labels)\n",
    "                print(batch_metrics)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            \n",
    "\n",
    "            if config.max_grad_norm:\n",
    "\n",
    "                scaler.unscale_(optimizer)\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "\n",
    "            \n",
    "\n",
    "            scaler.step(optimizer)\n",
    "\n",
    "            scaler.update()\n",
    "\n",
    "        else:\n",
    "\n",
    "            outputs = model(images, return_features=True)\n",
    "            loss, batch_metrics = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            \n",
    "\n",
    "            if config.max_grad_norm:\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "\n",
    "            \n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if scheduler:\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        \n",
    "\n",
    "        # Update loss and metrics\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        for k, v in batch_metrics.items():\n",
    "\n",
    "            metrics[k] += v\n",
    "\n",
    "        \n",
    "\n",
    "        # Update progress bar with detailed information\n",
    "\n",
    "        pbar.set_postfix({\n",
    "\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "\n",
    "            'avg_loss': f'{total_loss / (batch_idx + 1):.4f}',\n",
    "\n",
    "            'lr': scheduler.get_last_lr()[0] if scheduler else optimizer.param_groups[0]['lr']\n",
    "\n",
    "        })\n",
    "\n",
    "    \n",
    "\n",
    "    # Normalize metrics over all batches\n",
    "\n",
    "    metrics = {k: v / len(train_loader) for k, v in metrics.items()}\n",
    "\n",
    "    return total_loss / len(train_loader), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97353d49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.623502Z",
     "iopub.status.busy": "2024-11-30T23:51:05.623107Z",
     "iopub.status.idle": "2024-11-30T23:51:05.628619Z",
     "shell.execute_reply": "2024-11-30T23:51:05.627884Z"
    },
    "papermill": {
     "duration": 0.018179,
     "end_time": "2024-11-30T23:51:05.630170",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.611991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_topk_accuracy(outputs, labels, k):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Computes the top-k accuracy for the given outputs and labels.\n",
    "\n",
    "    \n",
    "\n",
    "    Args:\n",
    "\n",
    "        outputs (torch.Tensor or dict): Model outputs, expected as a tensor.\n",
    "\n",
    "        labels (torch.Tensor): Ground truth labels.\n",
    "\n",
    "        k (int): The 'k' in top-k accuracy.\n",
    "\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "\n",
    "        float: Top-k accuracy as a percentage.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    outputs = outputs['student_logits']  # Update the key to match your dictionary structure\n",
    "\n",
    "    \n",
    "\n",
    "    _, top_k_preds = outputs.topk(k, dim=1)\n",
    "\n",
    "    top_k_correct = top_k_preds.eq(labels.view(-1, 1).expand_as(top_k_preds))\n",
    "\n",
    "    return top_k_correct.any(dim=1).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70676fbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.649194Z",
     "iopub.status.busy": "2024-11-30T23:51:05.648954Z",
     "iopub.status.idle": "2024-11-30T23:51:05.668353Z",
     "shell.execute_reply": "2024-11-30T23:51:05.667567Z"
    },
    "papermill": {
     "duration": 0.030694,
     "end_time": "2024-11-30T23:51:05.669862",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.639168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 25.00%\n",
      "Top-3 Accuracy: 37.50%\n"
     ]
    }
   ],
   "source": [
    "def test_compute_topk_accuracy():\n",
    "    # Create synthetic outputs (logits)\n",
    "    batch_size = 8\n",
    "    num_classes = 5\n",
    "    outputs = {'student_logits': torch.randn(batch_size, num_classes)}\n",
    "\n",
    "    # Create synthetic labels\n",
    "    labels = torch.randint(0, num_classes, (batch_size,))\n",
    "\n",
    "    # Test the function for k = 1 and k = 3\n",
    "    for k in [1, 3]:\n",
    "        top_k_accuracy = compute_topk_accuracy(outputs, labels, k)\n",
    "        print(f\"Top-{k} Accuracy: {top_k_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Run the test\n",
    "test_compute_topk_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e862f387",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.690637Z",
     "iopub.status.busy": "2024-11-30T23:51:05.690002Z",
     "iopub.status.idle": "2024-11-30T23:51:05.696254Z",
     "shell.execute_reply": "2024-11-30T23:51:05.695497Z"
    },
    "papermill": {
     "duration": 0.018548,
     "end_time": "2024-11-30T23:51:05.697774",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.679226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_epoch(model, val_loader, criterion, config):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    metrics = defaultdict(float)\n",
    "\n",
    "    \n",
    "\n",
    "    pbar = tqdm(val_loader, desc='Validating')\n",
    "\n",
    "    \n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(pbar):\n",
    "\n",
    "            images, labels = images.to(config.device), labels.to(config.device)\n",
    "\n",
    "            \n",
    "\n",
    "            # Forward pass\n",
    "\n",
    "            outputs = model(images, return_features=True)\n",
    "\n",
    "            loss, batch_metrics = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            # Accumulate loss and metrics\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            metrics['top1_acc'] += compute_topk_accuracy(outputs, labels, 1)\n",
    "\n",
    "            metrics['top5_acc'] += compute_topk_accuracy(outputs, labels, 5)\n",
    "\n",
    "            metrics['top10_acc'] += compute_topk_accuracy(outputs, labels, 10)\n",
    "\n",
    "            \n",
    "\n",
    "            # Update progress bar\n",
    "\n",
    "            pbar.set_postfix({\n",
    "\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "\n",
    "                'avg_loss': f'{total_loss / (batch_idx + 1):.4f}'\n",
    "\n",
    "            })\n",
    "\n",
    "    \n",
    "\n",
    "    # Normalize metrics over all batches\n",
    "\n",
    "    metrics = {k: v / len(val_loader) for k, v in metrics.items()}\n",
    "\n",
    "    return total_loss / len(val_loader), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99d37185",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.716538Z",
     "iopub.status.busy": "2024-11-30T23:51:05.716292Z",
     "iopub.status.idle": "2024-11-30T23:51:05.719511Z",
     "shell.execute_reply": "2024-11-30T23:51:05.718845Z"
    },
    "papermill": {
     "duration": 0.014274,
     "end_time": "2024-11-30T23:51:05.721047",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.706773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec28dd57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.740198Z",
     "iopub.status.busy": "2024-11-30T23:51:05.739724Z",
     "iopub.status.idle": "2024-11-30T23:51:05.743523Z",
     "shell.execute_reply": "2024-11-30T23:51:05.742831Z"
    },
    "papermill": {
     "duration": 0.015026,
     "end_time": "2024-11-30T23:51:05.745073",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.730047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = GoogleLandmarksDataset(train_df, class_name_to_idx=class_name_to_idx, transform=transforms_train)\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    num_workers=N_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0902996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T23:51:05.764339Z",
     "iopub.status.busy": "2024-11-30T23:51:05.763870Z",
     "iopub.status.idle": "2024-12-01T09:12:18.985669Z",
     "shell.execute_reply": "2024-12-01T09:12:18.984580Z"
    },
    "papermill": {
     "duration": 33676.132792,
     "end_time": "2024-12-01T09:12:21.886888",
     "exception": false,
     "start_time": "2024-11-30T23:51:05.754096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39052a0434e84c309442a8f8f0834e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Starting Fold 0\n",
      "##############################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1875 [00:00<?, ?it/s]/tmp/ipykernel_23/959980901.py:61: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 1875/1875 [14:26<00:00,  2.16it/s, loss=8.2429, avg_loss=8.2833, lr=0.0001]\n",
      "Validating: 100%|██████████| 235/235 [02:12<00:00,  1.78it/s, loss=7.7995, avg_loss=7.3338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 8.2833 | Val Loss: 7.3338 | Top1 Acc: 0.17 | Top5 Acc: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:38<00:00,  2.47it/s, loss=8.3665, avg_loss=8.2984, lr=9.99e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.14it/s, loss=7.7649, avg_loss=7.3276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 8.2984 | Val Loss: 7.3276 | Top1 Acc: 0.18 | Top5 Acc: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:46<00:00,  2.45it/s, loss=8.1608, avg_loss=8.2907, lr=9.96e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.7608, avg_loss=7.3263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 8.2907 | Val Loss: 7.3263 | Top1 Acc: 0.18 | Top5 Acc: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:40<00:00,  2.46it/s, loss=8.3209, avg_loss=8.2832, lr=9.92e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:49<00:00,  2.14it/s, loss=7.7509, avg_loss=7.3258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 8.2832 | Val Loss: 7.3258 | Top1 Acc: 0.18 | Top5 Acc: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:40<00:00,  2.47it/s, loss=8.4308, avg_loss=8.2720, lr=9.87e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.7798, avg_loss=7.3247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 8.2720 | Val Loss: 7.3247 | Top1 Acc: 0.18 | Top5 Acc: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:43<00:00,  2.46it/s, loss=8.3802, avg_loss=8.2633, lr=9.81e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8056, avg_loss=7.3238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 8.2633 | Val Loss: 7.3238 | Top1 Acc: 0.18 | Top5 Acc: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:45<00:00,  2.45it/s, loss=8.1957, avg_loss=8.2575, lr=9.73e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.7841, avg_loss=7.3204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 8.2575 | Val Loss: 7.3204 | Top1 Acc: 0.18 | Top5 Acc: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:45<00:00,  2.45it/s, loss=8.0617, avg_loss=8.2453, lr=9.65e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:42<00:00,  2.30it/s, loss=7.7839, avg_loss=7.3173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 8.2453 | Val Loss: 7.3173 | Top1 Acc: 0.18 | Top5 Acc: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:38<00:00,  2.47it/s, loss=8.0467, avg_loss=8.2389, lr=9.55e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:42<00:00,  2.29it/s, loss=7.8119, avg_loss=7.3209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 8.2389 | Val Loss: 7.3209 | Top1 Acc: 0.18 | Top5 Acc: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:45<00:00,  2.45it/s, loss=8.3518, avg_loss=8.2296, lr=9.43e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.7956, avg_loss=7.3176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 8.2296 | Val Loss: 7.3176 | Top1 Acc: 0.18 | Top5 Acc: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:55<00:00,  2.42it/s, loss=8.0545, avg_loss=8.2223, lr=9.31e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8005, avg_loss=7.3153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 8.2223 | Val Loss: 7.3153 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [13:02<00:00,  2.39it/s, loss=8.2396, avg_loss=8.2140, lr=9.18e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.7875, avg_loss=7.3171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 8.2140 | Val Loss: 7.3171 | Top1 Acc: 0.18 | Top5 Acc: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:55<00:00,  2.42it/s, loss=8.0326, avg_loss=8.2032, lr=9.03e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8059, avg_loss=7.3119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 8.2032 | Val Loss: 7.3119 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:55<00:00,  2.42it/s, loss=8.4131, avg_loss=8.1942, lr=8.88e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:49<00:00,  2.14it/s, loss=7.8107, avg_loss=7.3114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 8.1942 | Val Loss: 7.3114 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:51<00:00,  2.43it/s, loss=8.1804, avg_loss=8.1903, lr=8.71e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8092, avg_loss=7.3080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 8.1903 | Val Loss: 7.3080 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:54<00:00,  2.42it/s, loss=8.2313, avg_loss=8.1781, lr=8.54e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:49<00:00,  2.14it/s, loss=7.8287, avg_loss=7.3097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 8.1781 | Val Loss: 7.3097 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:54<00:00,  2.42it/s, loss=7.9921, avg_loss=8.1676, lr=8.36e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.12it/s, loss=7.8105, avg_loss=7.3094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 8.1676 | Val Loss: 7.3094 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:54<00:00,  2.42it/s, loss=8.0030, avg_loss=8.1613, lr=8.16e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.7935, avg_loss=7.3037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 8.1613 | Val Loss: 7.3037 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:49<00:00,  2.44it/s, loss=8.1393, avg_loss=8.1532, lr=7.96e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:49<00:00,  2.14it/s, loss=7.7987, avg_loss=7.3028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 8.1532 | Val Loss: 7.3028 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:51<00:00,  2.43it/s, loss=8.2280, avg_loss=8.1456, lr=7.75e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:49<00:00,  2.14it/s, loss=7.8372, avg_loss=7.3037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 8.1456 | Val Loss: 7.3037 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:52<00:00,  2.43it/s, loss=8.1162, avg_loss=8.1391, lr=7.54e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:49<00:00,  2.14it/s, loss=7.8200, avg_loss=7.3000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 8.1391 | Val Loss: 7.3000 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:56<00:00,  2.41it/s, loss=8.0878, avg_loss=8.1286, lr=7.32e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.7989, avg_loss=7.3010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 8.1286 | Val Loss: 7.3010 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:58<00:00,  2.41it/s, loss=8.1125, avg_loss=8.1212, lr=7.09e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.12it/s, loss=7.8228, avg_loss=7.3006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 8.1212 | Val Loss: 7.3006 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:58<00:00,  2.41it/s, loss=7.6655, avg_loss=8.1184, lr=6.86e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8056, avg_loss=7.2973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 8.1184 | Val Loss: 7.2973 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [13:02<00:00,  2.40it/s, loss=8.2392, avg_loss=8.1063, lr=6.62e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:49<00:00,  2.14it/s, loss=7.8181, avg_loss=7.2989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 8.1063 | Val Loss: 7.2989 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:59<00:00,  2.41it/s, loss=8.0178, avg_loss=8.0985, lr=6.38e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:49<00:00,  2.14it/s, loss=7.8110, avg_loss=7.2965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 8.0985 | Val Loss: 7.2965 | Top1 Acc: 0.18 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:58<00:00,  2.41it/s, loss=8.0117, avg_loss=8.0926, lr=6.13e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8272, avg_loss=7.2969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 8.0926 | Val Loss: 7.2969 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:48<00:00,  2.44it/s, loss=8.1842, avg_loss=8.0839, lr=5.88e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8190, avg_loss=7.2955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 8.0839 | Val Loss: 7.2955 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:46<00:00,  2.45it/s, loss=7.9707, avg_loss=8.0800, lr=5.63e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8017, avg_loss=7.2954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 8.0800 | Val Loss: 7.2954 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:44<00:00,  2.45it/s, loss=7.9570, avg_loss=8.0738, lr=5.38e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.12it/s, loss=7.7959, avg_loss=7.2923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 8.0738 | Val Loss: 7.2923 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:50<00:00,  2.44it/s, loss=8.1468, avg_loss=8.0628, lr=5.13e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8095, avg_loss=7.2934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 8.0628 | Val Loss: 7.2934 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:52<00:00,  2.43it/s, loss=8.3151, avg_loss=8.0598, lr=4.87e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8053, avg_loss=7.2918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 8.0598 | Val Loss: 7.2918 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:49<00:00,  2.44it/s, loss=7.8780, avg_loss=8.0552, lr=4.62e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8067, avg_loss=7.2918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 8.0552 | Val Loss: 7.2918 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:50<00:00,  2.43it/s, loss=8.2519, avg_loss=8.0461, lr=4.37e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8078, avg_loss=7.2937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 8.0461 | Val Loss: 7.2937 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:58<00:00,  2.41it/s, loss=8.2275, avg_loss=8.0424, lr=4.12e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:49<00:00,  2.14it/s, loss=7.8084, avg_loss=7.2881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 8.0424 | Val Loss: 7.2881 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:52<00:00,  2.43it/s, loss=7.8135, avg_loss=8.0346, lr=3.87e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:49<00:00,  2.14it/s, loss=7.8020, avg_loss=7.2906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 8.0346 | Val Loss: 7.2906 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:57<00:00,  2.41it/s, loss=7.8123, avg_loss=8.0315, lr=3.62e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8279, avg_loss=7.2911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 8.0315 | Val Loss: 7.2911 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [12:59<00:00,  2.41it/s, loss=8.0082, avg_loss=8.0244, lr=3.38e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:50<00:00,  2.13it/s, loss=7.8243, avg_loss=7.2894]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 8.0244 | Val Loss: 7.2894 | Top1 Acc: 0.19 | Top5 Acc: 0.25\n",
      "Early stopping triggered at epoch 38\n",
      "Summary of Fold Metrics:\n",
      "{'fold': 0, 'train_loss': 8.024432688649496, 'val_loss': 7.28944915203338, 'top1_acc': 0.18743085106636614, 'top5_acc': 0.25225797872594063, 'top10_acc': 0.2754295212791321}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "teacher_model = GoogleLandmarksModel(text_embeddings=text_embeddings, model_name=\"RN101\", device=device)\n",
    "teacher_model = teacher_model.float()\n",
    "\n",
    "checkpoint = torch.load('/kaggle/input/k/thangchu/training-clip-baseline-on-landmarks-index-set/clip_landmark_results/best_val_loss_model_fold-0.pth', weights_only = False)\n",
    "teacher_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "teacher_model.to(device)\n",
    "\n",
    "student_model = timm.create_model(\"resnet18\", pretrained=True, num_classes=N_CLASSES)\n",
    "student_model = student_model.float()\n",
    "checkpoint = torch.load('/kaggle/input/checkpointss/pytorch/default/1/best_student_model_fold0.pth',weights_only = False)\n",
    "student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Initialize the improved distillation model\n",
    "\n",
    "distillation_model = CrossModalDistillationModel(\n",
    "\n",
    "    teacher_model=teacher_model,\n",
    "\n",
    "    student_model=student_model,\n",
    "\n",
    "    text_embeddings=text_embeddings.to(device),\n",
    "\n",
    "    projection_dim=512  # Same dimension as CLIP's feature space\n",
    "\n",
    ")\n",
    "\n",
    "distillation_checkpoint_path = '/kaggle/input/checkpointss/pytorch/default/1/best_model_fold0.pth'\n",
    "distillation_checkpoint = torch.load(distillation_checkpoint_path, weights_only = False ,map_location=device)\n",
    "\n",
    "# Load the state_dict into the distillation model\n",
    "distillation_model.load_state_dict(distillation_checkpoint['model_state_dict'])\n",
    "distillation_model.to(device)\n",
    "\n",
    "# (Optional) Load optimizer state if continuing training\n",
    "\n",
    "\n",
    "# Optimizer with weight decay\n",
    "\n",
    "optimizer = AdamW([\n",
    "\n",
    "    {'params': distillation_model.student.parameters(), 'lr': 1e-4},\n",
    "\n",
    "    {'params': distillation_model.projection_head.parameters(), 'lr': 1e-4}\n",
    "\n",
    "], weight_decay=0.01)\n",
    "\n",
    "optimizer.load_state_dict(distillation_checkpoint['optimizer_state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "# Scheduler with warmup\n",
    "\n",
    "num_training_steps = len(train_dl) * EPOCHS\n",
    "\n",
    "num_warmup_steps = min(1000, num_training_steps // 20)  # 10% of training steps or 1000, whichever is smaller\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "\n",
    "    optimizer, \n",
    "\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "\n",
    "    num_training_steps=num_training_steps\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Training loop with validation\n",
    "\n",
    "patience = EARLY_STOPPING_EPOCH\n",
    "\n",
    "patience_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "scaler = GradScaler() if USE_AMP else None\n",
    "\n",
    "\n",
    "\n",
    "sfk = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "training_folds = [0] \n",
    "\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(sfk.split(train_df, train_df.landmark_id.tolist())):\n",
    "    if fold not in training_folds:\n",
    "        continue\n",
    "\n",
    "    print(f\"{'#'*30}\\nStarting Fold {fold}\\n{'#'*30}\")\n",
    "\n",
    "    # Prepare datasets and dataloaders\n",
    "    df_train = train_df.iloc[trn_idx]\n",
    "    df_valid = train_df.iloc[val_idx]\n",
    "\n",
    "    train_ds = GoogleLandmarksDataset(df_train, class_name_to_idx=class_name_to_idx, transform=transforms_train)\n",
    "    valid_ds = GoogleLandmarksDataset(df_valid, class_name_to_idx=class_name_to_idx, transform=transforms_val)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS, drop_last=True, pin_memory=True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=N_WORKERS, drop_last=False, pin_memory=True)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_metrics = train_epoch(\n",
    "            model=distillation_model,\n",
    "            train_loader=train_dl,\n",
    "            criterion=EnhancedDistillationLoss(Config()),\n",
    "            optimizer=optimizer,\n",
    "            config=Config(),\n",
    "            scheduler=scheduler\n",
    "        )\n",
    "\n",
    "        val_loss, val_metrics = validate_epoch(\n",
    "            model=distillation_model,\n",
    "            val_loader=valid_dl,\n",
    "            criterion=EnhancedDistillationLoss(Config()),\n",
    "            config=Config()\n",
    "        )\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "              f\"Top1 Acc: {val_metrics['top1_acc']:.2f} | Top5 Acc: {val_metrics['top5_acc']:.2f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "        'model_state_dict': distillation_model.student.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "        'epoch': epoch,\n",
    "    }, f'{OUTPUT_DIR}/best_student_model_fold{fold}.pth')\n",
    "            torch.save({\n",
    "                'fold': fold,\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': distillation_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "            }, f'{OUTPUT_DIR}/best_model_fold{fold}.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    fold_metrics.append({\n",
    "        'fold': fold,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'top1_acc': val_metrics['top1_acc'],\n",
    "        'top5_acc': val_metrics['top5_acc'],\n",
    "        'top10_acc': val_metrics['top10_acc'],\n",
    "    })\n",
    "\n",
    "# Print overall metrics\n",
    "print(\"Summary of Fold Metrics:\")\n",
    "for metric in fold_metrics:\n",
    "    print(metric)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5883095,
     "sourceId": 9635661,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5883097,
     "sourceId": 9635664,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5883577,
     "sourceId": 9636294,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5883578,
     "sourceId": 9636295,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5883713,
     "sourceId": 9636477,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5882766,
     "sourceId": 9720780,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5935937,
     "sourceId": 9828230,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6123513,
     "sourceId": 9956472,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 204129443,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 210231673,
     "sourceType": "kernelVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 179277,
     "modelInstanceId": 156844,
     "sourceId": 184023,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33735.037782,
   "end_time": "2024-12-01T09:12:32.563986",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-30T23:50:17.526204",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0192e06ae27545d09190358b3d4a6f21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0899c9b18dd94467944bd1e8b6855277": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_aa5521a8f01f4127b3dd5d46ea4336e1",
       "placeholder": "​",
       "style": "IPY_MODEL_af31ad81319a45b58472414d4f7aea16",
       "value": "model.safetensors: 100%"
      }
     },
     "245c605e61ed4858ac0eb9786c68c228": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0192e06ae27545d09190358b3d4a6f21",
       "placeholder": "​",
       "style": "IPY_MODEL_9b4358f084f84a148d4ad4278a66c5f3",
       "value": " 46.8M/46.8M [00:00&lt;00:00, 126MB/s]"
      }
     },
     "39052a0434e84c309442a8f8f0834e60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0899c9b18dd94467944bd1e8b6855277",
        "IPY_MODEL_524711e3fec44246b571da2f975564cf",
        "IPY_MODEL_245c605e61ed4858ac0eb9786c68c228"
       ],
       "layout": "IPY_MODEL_8dad5d78182643708b888d9289ca3bf5"
      }
     },
     "524711e3fec44246b571da2f975564cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_baa16d1029814f799badd4d5b6e891ca",
       "max": 46807446.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_70750e1e5bf8471f9492cbece5abfffa",
       "value": 46807446.0
      }
     },
     "70750e1e5bf8471f9492cbece5abfffa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8dad5d78182643708b888d9289ca3bf5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b4358f084f84a148d4ad4278a66c5f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aa5521a8f01f4127b3dd5d46ea4336e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af31ad81319a45b58472414d4f7aea16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "baa16d1029814f799badd4d5b6e891ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
