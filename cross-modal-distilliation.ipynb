{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21480551",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-22T06:07:33.169508Z",
     "iopub.status.busy": "2024-11-22T06:07:33.169227Z",
     "iopub.status.idle": "2024-11-22T06:07:46.029211Z",
     "shell.execute_reply": "2024-11-22T06:07:46.028102Z"
    },
    "papermill": {
     "duration": 12.869568,
     "end_time": "2024-11-22T06:07:46.031346",
     "exception": false,
     "start_time": "2024-11-22T06:07:33.161778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\r\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-4vf4z0c0\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-4vf4z0c0\r\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting ftfy (from clip==1.0)\r\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (21.3)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2024.5.15)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.4)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.4.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.19.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->clip==1.0) (3.1.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (2024.6.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\r\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: clip\r\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=f55c5b23eb61e929a1b247f5fc25a6c5702e12081d78b97c7a114bb0d6d7dc89\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-grr4z16a/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\r\n",
      "Successfully built clip\r\n",
      "Installing collected packages: ftfy, clip\r\n",
      "Successfully installed clip-1.0 ftfy-6.3.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa6dc01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:07:46.047168Z",
     "iopub.status.busy": "2024-11-22T06:07:46.046528Z",
     "iopub.status.idle": "2024-11-22T06:07:56.519144Z",
     "shell.execute_reply": "2024-11-22T06:07:56.517697Z"
    },
    "papermill": {
     "duration": 10.482275,
     "end_time": "2024-11-22T06:07:56.521553",
     "exception": false,
     "start_time": "2024-11-22T06:07:46.039278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.4.17)\r\n",
      "Collecting albumentations\r\n",
      "  Downloading albumentations-1.4.21-py3-none-any.whl.metadata (31 kB)\r\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.14.1)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.2)\r\n",
      "Requirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (2.9.2)\r\n",
      "Collecting albucore==0.0.20 (from albumentations)\r\n",
      "  Downloading albucore-0.0.20-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.2.0)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.10.0.84)\r\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.20->albumentations)\r\n",
      "  Downloading stringzilla-3.10.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting simsimd>=5.9.2 (from albucore==0.0.20->albumentations)\r\n",
      "  Downloading simsimd-6.1.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\r\n",
      "Downloading albumentations-1.4.21-py3-none-any.whl (227 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.9/227.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading albucore-0.0.20-py3-none-any.whl (12 kB)\r\n",
      "Downloading simsimd-6.1.1-cp310-cp310-manylinux_2_28_x86_64.whl (606 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.4/606.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading stringzilla-3.10.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (291 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.7/291.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: stringzilla, simsimd, albucore, albumentations\r\n",
      "  Attempting uninstall: albucore\r\n",
      "    Found existing installation: albucore 0.0.17\r\n",
      "    Uninstalling albucore-0.0.17:\r\n",
      "      Successfully uninstalled albucore-0.0.17\r\n",
      "  Attempting uninstall: albumentations\r\n",
      "    Found existing installation: albumentations 1.4.17\r\n",
      "    Uninstalling albumentations-1.4.17:\r\n",
      "      Successfully uninstalled albumentations-1.4.17\r\n",
      "Successfully installed albucore-0.0.20 albumentations-1.4.21 simsimd-6.1.1 stringzilla-3.10.10\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3cc430",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:07:56.539961Z",
     "iopub.status.busy": "2024-11-22T06:07:56.539631Z",
     "iopub.status.idle": "2024-11-22T06:08:05.437455Z",
     "shell.execute_reply": "2024-11-22T06:08:05.436729Z"
    },
    "papermill": {
     "duration": 8.909471,
     "end_time": "2024-11-22T06:08:05.439737",
     "exception": false,
     "start_time": "2024-11-22T06:07:56.530266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gc\n",
    "\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "\n",
    "import math, random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "\n",
    "import timm\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import clip\n",
    "\n",
    "\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import wandb\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ee42a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:05.455726Z",
     "iopub.status.busy": "2024-11-22T06:08:05.455178Z",
     "iopub.status.idle": "2024-11-22T06:08:05.463380Z",
     "shell.execute_reply": "2024-11-22T06:08:05.462621Z"
    },
    "papermill": {
     "duration": 0.018087,
     "end_time": "2024-11-22T06:08:05.465201",
     "exception": false,
     "start_time": "2024-11-22T06:08:05.447114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "N_WORKERS = os.cpu_count() \n",
    "\n",
    "USE_AMP = False # can change True if using T4 or newer than Ampere\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "CLIP_MODEL_NAME = \"RN101\"\n",
    "\n",
    "IMG_SIZE = [224, 224]\n",
    "\n",
    "AUG_PROB = 0.2\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "if DEBUG:\n",
    "\n",
    "    EPOCHS = 3\n",
    "\n",
    "GRAD_ACC = 1\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "MAX_GRAD_NORM = None\n",
    "\n",
    "EARLY_STOPPING_EPOCH = 3\n",
    "\n",
    "OUTPUT_DIR = f'clip_landmark_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e37448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:05.482835Z",
     "iopub.status.busy": "2024-11-22T06:08:05.482553Z",
     "iopub.status.idle": "2024-11-22T06:08:05.486984Z",
     "shell.execute_reply": "2024-11-22T06:08:05.486183Z"
    },
    "papermill": {
     "duration": 0.015218,
     "end_time": "2024-11-22T06:08:05.488726",
     "exception": false,
     "start_time": "2024-11-22T06:08:05.473508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ef18b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:05.505662Z",
     "iopub.status.busy": "2024-11-22T06:08:05.505383Z",
     "iopub.status.idle": "2024-11-22T06:08:06.522862Z",
     "shell.execute_reply": "2024-11-22T06:08:06.521900Z"
    },
    "papermill": {
     "duration": 1.028074,
     "end_time": "2024-11-22T06:08:06.524875",
     "exception": false,
     "start_time": "2024-11-22T06:08:05.496801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>category</th>\n",
       "      <th>supercategory</th>\n",
       "      <th>hierarchical_label</th>\n",
       "      <th>natural_or_human_made</th>\n",
       "      <th>cleaned_supercategory</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>image_path</th>\n",
       "      <th>landmark_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87a5dfadcaeba144</td>\n",
       "      <td>93036</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Nav...</td>\n",
       "      <td>naval base</td>\n",
       "      <td>harbor</td>\n",
       "      <td>human-made</td>\n",
       "      <td>naval base</td>\n",
       "      <td>Guantánamo Province , Cuba</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p3...</td>\n",
       "      <td>Naval Station Guantanamo Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53824bfa2b3e569c</td>\n",
       "      <td>93036</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Nav...</td>\n",
       "      <td>naval base</td>\n",
       "      <td>harbor</td>\n",
       "      <td>human-made</td>\n",
       "      <td>naval base</td>\n",
       "      <td>Guantánamo Province , Cuba</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p2...</td>\n",
       "      <td>Naval Station Guantanamo Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>080a99cff9666667</td>\n",
       "      <td>93036</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Nav...</td>\n",
       "      <td>naval base</td>\n",
       "      <td>harbor</td>\n",
       "      <td>human-made</td>\n",
       "      <td>naval base</td>\n",
       "      <td>Guantánamo Province , Cuba</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p1...</td>\n",
       "      <td>Naval Station Guantanamo Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b86710311289fa90</td>\n",
       "      <td>93036</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Nav...</td>\n",
       "      <td>naval base</td>\n",
       "      <td>harbor</td>\n",
       "      <td>human-made</td>\n",
       "      <td>naval base</td>\n",
       "      <td>Guantánamo Province , Cuba</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p4...</td>\n",
       "      <td>Naval Station Guantanamo Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5554c986662c2587</td>\n",
       "      <td>93036</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Nav...</td>\n",
       "      <td>naval base</td>\n",
       "      <td>harbor</td>\n",
       "      <td>human-made</td>\n",
       "      <td>naval base</td>\n",
       "      <td>Guantánamo Province , Cuba</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p2...</td>\n",
       "      <td>Naval Station Guantanamo Bay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  landmark_id  \\\n",
       "0  87a5dfadcaeba144        93036   \n",
       "1  53824bfa2b3e569c        93036   \n",
       "2  080a99cff9666667        93036   \n",
       "3  b86710311289fa90        93036   \n",
       "4  5554c986662c2587        93036   \n",
       "\n",
       "                                            category supercategory  \\\n",
       "0  http://commons.wikimedia.org/wiki/Category:Nav...    naval base   \n",
       "1  http://commons.wikimedia.org/wiki/Category:Nav...    naval base   \n",
       "2  http://commons.wikimedia.org/wiki/Category:Nav...    naval base   \n",
       "3  http://commons.wikimedia.org/wiki/Category:Nav...    naval base   \n",
       "4  http://commons.wikimedia.org/wiki/Category:Nav...    naval base   \n",
       "\n",
       "  hierarchical_label natural_or_human_made cleaned_supercategory  \\\n",
       "0             harbor            human-made            naval base   \n",
       "1             harbor            human-made            naval base   \n",
       "2             harbor            human-made            naval base   \n",
       "3             harbor            human-made            naval base   \n",
       "4             harbor            human-made            naval base   \n",
       "\n",
       "                     location country  \\\n",
       "0  Guantánamo Province , Cuba    Cuba   \n",
       "1  Guantánamo Province , Cuba    Cuba   \n",
       "2  Guantánamo Province , Cuba    Cuba   \n",
       "3  Guantánamo Province , Cuba    Cuba   \n",
       "4  Guantánamo Province , Cuba    Cuba   \n",
       "\n",
       "                                          image_path  \\\n",
       "0  /kaggle/input/google-landmarks-v2-index-set-p3...   \n",
       "1  /kaggle/input/google-landmarks-v2-index-set-p2...   \n",
       "2  /kaggle/input/google-landmarks-v2-index-set-p1...   \n",
       "3  /kaggle/input/google-landmarks-v2-index-set-p4...   \n",
       "4  /kaggle/input/google-landmarks-v2-index-set-p2...   \n",
       "\n",
       "                  landmark_name  \n",
       "0  Naval Station Guantanamo Bay  \n",
       "1  Naval Station Guantanamo Bay  \n",
       "2  Naval Station Guantanamo Bay  \n",
       "3  Naval Station Guantanamo Bay  \n",
       "4  Naval Station Guantanamo Bay  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/google-landmarks-v2-index-subset-metadata/cleaned_landmark_index_subset_150k_with_locations_v4.csv\")\n",
    "\n",
    "if DEBUG:\n",
    "\n",
    "    # Reduce to 1000 samples for quick debugging\n",
    "\n",
    "    train_df = train_df.sample(1000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86183618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:06.541748Z",
     "iopub.status.busy": "2024-11-22T06:08:06.541419Z",
     "iopub.status.idle": "2024-11-22T06:08:06.565613Z",
     "shell.execute_reply": "2024-11-22T06:08:06.564981Z"
    },
    "papermill": {
     "duration": 0.033882,
     "end_time": "2024-11-22T06:08:06.567164",
     "exception": false,
     "start_time": "2024-11-22T06:08:06.533282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_CLASSES = train_df.landmark_name.nunique()\n",
    "\n",
    "class_names = train_df.landmark_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d1941ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:06.583016Z",
     "iopub.status.busy": "2024-11-22T06:08:06.582766Z",
     "iopub.status.idle": "2024-11-22T06:08:17.174320Z",
     "shell.execute_reply": "2024-11-22T06:08:17.173314Z"
    },
    "papermill": {
     "duration": 10.602103,
     "end_time": "2024-11-22T06:08:17.176592",
     "exception": false,
     "start_time": "2024-11-22T06:08:06.574489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 278M/278M [00:03<00:00, 93.1MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load CLIP model\n",
    "\n",
    "embedding_device = device\n",
    "\n",
    "model, _ = clip.load(CLIP_MODEL_NAME, device=embedding_device)\n",
    "\n",
    "\n",
    "\n",
    "# Define class names and tokenize\n",
    "\n",
    "text_prompts = [f\"A photo of {name} or its part\" for name in class_names]\n",
    "\n",
    "text_tokens = clip.tokenize(text_prompts).to(embedding_device)\n",
    "\n",
    "\n",
    "\n",
    "# Compute text embeddings\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    text_embeddings = model.encode_text(text_tokens)\n",
    "\n",
    "text_embeddings = text_embeddings / text_embeddings.norm(dim=-1, keepdim=True)  # Normalize for cosine similarity\n",
    "\n",
    "text_embeddings = text_embeddings.float()\n",
    "torch.save(text_embeddings,'text_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b6cccc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.196124Z",
     "iopub.status.busy": "2024-11-22T06:08:17.195638Z",
     "iopub.status.idle": "2024-11-22T06:08:17.201439Z",
     "shell.execute_reply": "2024-11-22T06:08:17.200688Z"
    },
    "papermill": {
     "duration": 0.017362,
     "end_time": "2024-11-22T06:08:17.203005",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.185643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text_embeddings = torch.load(\"/kaggle/input/text_embeddings/pytorch/default/1/text_embeddings.pt\", weights_only=True)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"text_embeddings = torch.load(\"/kaggle/input/text_embeddings/pytorch/default/1/text_embeddings.pt\", weights_only=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd09fcff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.222093Z",
     "iopub.status.busy": "2024-11-22T06:08:17.221360Z",
     "iopub.status.idle": "2024-11-22T06:08:17.226146Z",
     "shell.execute_reply": "2024-11-22T06:08:17.225427Z"
    },
    "papermill": {
     "duration": 0.015959,
     "end_time": "2024-11-22T06:08:17.227705",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.211746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_name_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "idx_to_class_name = {idx: class_name for class_name, idx in class_name_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60acf3a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.245961Z",
     "iopub.status.busy": "2024-11-22T06:08:17.245706Z",
     "iopub.status.idle": "2024-11-22T06:08:17.263458Z",
     "shell.execute_reply": "2024-11-22T06:08:17.262743Z"
    },
    "papermill": {
     "duration": 0.028866,
     "end_time": "2024-11-22T06:08:17.265181",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.236315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "transforms_train = A.Compose([\n",
    "\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=AUG_PROB),\n",
    "\n",
    "    A.OneOf([\n",
    "\n",
    "        A.MotionBlur(blur_limit=5),\n",
    "\n",
    "        A.MedianBlur(blur_limit=5),\n",
    "\n",
    "        A.GaussianBlur(blur_limit=5),\n",
    "\n",
    "        A.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "\n",
    "    ], p=AUG_PROB),\n",
    "\n",
    "\n",
    "\n",
    "    A.OneOf([\n",
    "\n",
    "        A.OpticalDistortion(distort_limit=1.0),\n",
    "\n",
    "        A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "\n",
    "        A.ElasticTransform(alpha=3),\n",
    "\n",
    "    ], p=AUG_PROB),\n",
    "\n",
    "\n",
    "\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=AUG_PROB),\n",
    "\n",
    "    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "\n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=1, min_height=8, min_width=8, p=AUG_PROB),    \n",
    "\n",
    "    A.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], \n",
    "\n",
    "                         std=[0.26862954, 0.26130258, 0.27577711])\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "transforms_val = A.Compose([\n",
    "\n",
    "    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "\n",
    "    A.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], \n",
    "\n",
    "                         std=[0.26862954, 0.26130258, 0.27577711])\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6eb61a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.284087Z",
     "iopub.status.busy": "2024-11-22T06:08:17.283628Z",
     "iopub.status.idle": "2024-11-22T06:08:17.289878Z",
     "shell.execute_reply": "2024-11-22T06:08:17.289047Z"
    },
    "papermill": {
     "duration": 0.01781,
     "end_time": "2024-11-22T06:08:17.291462",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.273652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GoogleLandmarksDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, class_name_to_idx, transform=None):\n",
    "\n",
    "        self.df = df\n",
    "\n",
    "        self.class_name_to_idx = class_name_to_idx  # Maps class name to index\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        t = self.df.iloc[idx]\n",
    "\n",
    "        class_name = t['landmark_name']\n",
    "\n",
    "        class_name_idx = self.class_name_to_idx[class_name]\n",
    "\n",
    "        \n",
    "\n",
    "        p = f'{t[\"image_path\"]}'\n",
    "\n",
    "        img = Image.open(p)\n",
    "\n",
    "        img = np.array(img)\n",
    "\n",
    "            \n",
    "\n",
    "        # Apply transformations if provided\n",
    "\n",
    "        if self.transform:\n",
    "\n",
    "            img = self.transform(image=np.array(img))['image']\n",
    "\n",
    "        \n",
    "\n",
    "        # Convert image to tensor if needed\n",
    "\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "\n",
    "        \n",
    "\n",
    "        return img, class_name_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2a64c50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.310351Z",
     "iopub.status.busy": "2024-11-22T06:08:17.310103Z",
     "iopub.status.idle": "2024-11-22T06:08:17.317974Z",
     "shell.execute_reply": "2024-11-22T06:08:17.317294Z"
    },
    "papermill": {
     "duration": 0.019251,
     "end_time": "2024-11-22T06:08:17.319412",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.300161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CrossModalDistillationModel(nn.Module):\n",
    "    def __init__(self, teacher_model, student_model, text_embeddings, projection_dim=512):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher_model\n",
    "        self.student = student_model\n",
    "        self.text_embeddings = text_embeddings  # Precomputed text embeddings from teacher\n",
    "\n",
    "        # Freeze teacher model parameters\n",
    "        for param in self.teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Get the input features dimension for the student model\n",
    "        in_features = student_model.get_classifier().in_features\n",
    "\n",
    "        # Projection head for the student model\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, projection_dim),\n",
    "            nn.BatchNorm1d(projection_dim)  # BatchNorm for stability\n",
    "        )\n",
    "        \n",
    "        # Classification head for the student model\n",
    "        self.classifier = nn.Linear(in_features, student_model.get_classifier().out_features)\n",
    "        \n",
    "        # Temperature parameter for distillation\n",
    "        self.temperature = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "\n",
    "    def forward(self, images, return_features=True):\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        # Forward pass through the teacher model\n",
    "        with torch.no_grad():\n",
    "            teacher_logits, teacher_features = self.teacher(images)  # Directly compute similarity scores\n",
    "            teacher_logits = teacher_logits * self.temperature.exp()\n",
    "\n",
    "        # Forward pass through the student model\n",
    "        student_features = self.student.forward_features(images)  # Extract features\n",
    "        student_features = F.adaptive_avg_pool2d(student_features, (1, 1))\n",
    "        student_features = student_features.view(batch_size, -1)\n",
    "\n",
    "        # Project student features to the teacher's feature space\n",
    "        student_projected = self.projection_head(student_features)\n",
    "        student_projected = F.normalize(student_projected, dim=-1)\n",
    "\n",
    "        # Compute classification logits for the student\n",
    "        student_logits = self.classifier(student_features)\n",
    "\n",
    "        # Return a dictionary of logits and features if required\n",
    "        if return_features:\n",
    "            return {\n",
    "                'teacher_logits': teacher_logits,\n",
    "                'student_logits': student_logits,\n",
    "                'teacher_features': teacher_features,  # Teacher features are not explicitly exposed here\n",
    "                'student_projected': student_projected,\n",
    "                'student_features': student_features\n",
    "            }\n",
    "\n",
    "        return student_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0482190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.337313Z",
     "iopub.status.busy": "2024-11-22T06:08:17.337073Z",
     "iopub.status.idle": "2024-11-22T06:08:17.342749Z",
     "shell.execute_reply": "2024-11-22T06:08:17.342065Z"
    },
    "papermill": {
     "duration": 0.016608,
     "end_time": "2024-11-22T06:08:17.344532",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.327924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GoogleLandmarksModel(nn.Module):\n",
    "    def __init__(self, text_embeddings, model_name=CLIP_MODEL_NAME, device=device):\n",
    "        super(GoogleLandmarksModel, self).__init__()\n",
    "        # Load the CLIP model\n",
    "        self.model, _ = clip.load(model_name, device=device)\n",
    "        \n",
    "        # Store the precomputed text embeddings\n",
    "        self.text_embeddings = text_embeddings\n",
    "        self.text_embeddings.requires_grad = False\n",
    "        \n",
    "        # Freeze the text encoder to save memory and computation\n",
    "        for param in self.model.transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, images):\n",
    "        # Compute image embeddings\n",
    "        image_embeddings = self.model.encode_image(images)\n",
    "        \n",
    "        # Normalize image embeddings without in-place operation\n",
    "        image_embeddings = image_embeddings / image_embeddings.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Check and match data types for mixed precision\n",
    "        if image_embeddings.dtype != self.text_embeddings.dtype:\n",
    "            text_embeddings = self.text_embeddings.to(image_embeddings.dtype)\n",
    "        else:\n",
    "            text_embeddings = self.text_embeddings\n",
    "        \n",
    "        # Compute cosine similarity with text embeddings\n",
    "        similarity = image_embeddings @ self.text_embeddings.T\n",
    "        return similarity, image_embeddings  # Similarity scores for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f80eb5db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.362937Z",
     "iopub.status.busy": "2024-11-22T06:08:17.362667Z",
     "iopub.status.idle": "2024-11-22T06:08:17.367143Z",
     "shell.execute_reply": "2024-11-22T06:08:17.366516Z"
    },
    "papermill": {
     "duration": 0.01533,
     "end_time": "2024-11-22T06:08:17.368696",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.353366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.alpha = 0.2\n",
    "\n",
    "        self.beta = 0.2\n",
    "\n",
    "        self.gamma = 0.5\n",
    "\n",
    "        self.temperature = 2.0\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.batch_size = BATCH_SIZE\n",
    "\n",
    "        self.n_workers = N_WORKERS\n",
    "\n",
    "        self.max_grad_norm = MAX_GRAD_NORM\n",
    "\n",
    "        self.log_interval = 100\n",
    "\n",
    "        self.use_amp = False\n",
    "\n",
    "        self.use_wandb = False  # Set to True if using wandb\n",
    "\n",
    "        self.warmup_steps = 100\n",
    "\n",
    "        self.gradient_accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c91e1b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.387794Z",
     "iopub.status.busy": "2024-11-22T06:08:17.387543Z",
     "iopub.status.idle": "2024-11-22T06:08:17.396678Z",
     "shell.execute_reply": "2024-11-22T06:08:17.395843Z"
    },
    "papermill": {
     "duration": 0.020457,
     "end_time": "2024-11-22T06:08:17.398306",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.377849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class EnhancedDistillationLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.alpha = config.alpha  # KD loss weight\n",
    "\n",
    "        self.beta = config.beta    # Feature alignment weight\n",
    "\n",
    "        self.gamma = config.gamma  # CE loss weight\n",
    "\n",
    "        self.T = config.temperature\n",
    "\n",
    "        self.contrastive_weight = 0.1  # Weight for contrastive loss\n",
    "\n",
    "        \n",
    "\n",
    "    def contrastive_loss(self, features, labels):\n",
    "\n",
    "        # Implement contrastive loss between positive pairs\n",
    "\n",
    "        similarity = torch.matmul(features, features.t())\n",
    "\n",
    "        mask = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "\n",
    "        \n",
    "\n",
    "        # Temperature-scaled similarities\n",
    "\n",
    "        similarity = similarity / self.T\n",
    "\n",
    "        \n",
    "\n",
    "        # Positive and negative pairs\n",
    "\n",
    "        exp_sim = torch.exp(similarity)\n",
    "\n",
    "        pos_sim = exp_sim * mask\n",
    "\n",
    "        neg_sim = exp_sim * (1 - mask)\n",
    "\n",
    "        \n",
    "\n",
    "        loss = -torch.log(\n",
    "\n",
    "            pos_sim.sum(1) / (pos_sim.sum(1) + neg_sim.sum(1))\n",
    "\n",
    "        ).mean()\n",
    "\n",
    "        \n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "\n",
    "        teacher_logits = outputs['teacher_logits'].float()\n",
    "\n",
    "        student_logits = outputs['student_logits'].float()\n",
    "\n",
    "        teacher_features = outputs['teacher_features'].float()\n",
    "\n",
    "        student_projected = outputs['student_projected'].float()\n",
    "\n",
    "        \n",
    "\n",
    "        # 1. Knowledge Distillation Loss\n",
    "\n",
    "        kd_loss = F.kl_div(\n",
    "\n",
    "            F.log_softmax(student_logits / self.T, dim=1),\n",
    "\n",
    "            F.softmax(teacher_logits / self.T, dim=1),\n",
    "\n",
    "            reduction=\"batchmean\"\n",
    "\n",
    "        ) * (self.T ** 2)\n",
    "\n",
    "        \n",
    "\n",
    "        # 2. Feature Alignment Loss\n",
    "\n",
    "        feature_loss = F.mse_loss(student_projected, teacher_features)\n",
    "\n",
    "        \n",
    "\n",
    "        # 3. Cross Entropy Loss\n",
    "\n",
    "        ce_loss = F.cross_entropy(student_logits, labels)\n",
    "\n",
    "        \n",
    "\n",
    "        # 4. Contrastive Loss\n",
    "\n",
    "        cont_loss = self.contrastive_loss(student_projected, labels)\n",
    "\n",
    "        \n",
    "\n",
    "        total_loss = (\n",
    "\n",
    "            self.alpha * kd_loss +\n",
    "\n",
    "            self.beta * feature_loss +\n",
    "\n",
    "            self.gamma * ce_loss +\n",
    "\n",
    "            self.contrastive_weight * cont_loss\n",
    "\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        return total_loss, {\n",
    "\n",
    "            'kd_loss': kd_loss.item(),\n",
    "\n",
    "            'feature_loss': feature_loss.item(),\n",
    "\n",
    "            'ce_loss': ce_loss.item(),\n",
    "\n",
    "            'cont_loss': cont_loss.item()\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60f0df3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.416239Z",
     "iopub.status.busy": "2024-11-22T06:08:17.415975Z",
     "iopub.status.idle": "2024-11-22T06:08:17.424913Z",
     "shell.execute_reply": "2024-11-22T06:08:17.424083Z"
    },
    "papermill": {
     "duration": 0.019757,
     "end_time": "2024-11-22T06:08:17.426403",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.406646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, config, scheduler=None):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    metrics = defaultdict(float)  # Tracks additional metrics\n",
    "\n",
    "    scaler = GradScaler() if config.use_amp else None\n",
    "\n",
    "    \n",
    "\n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "\n",
    "    \n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "\n",
    "        images, labels = images.to(config.device), labels.to(config.device)\n",
    "\n",
    "        \n",
    "\n",
    "        # Mixed precision training\n",
    "\n",
    "        if config.use_amp:\n",
    "\n",
    "            with autocast():\n",
    "\n",
    "                outputs = model(images, return_features=True)\n",
    "\n",
    "                loss, batch_metrics = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            \n",
    "\n",
    "            if config.max_grad_norm:\n",
    "\n",
    "                scaler.unscale_(optimizer)\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "\n",
    "            \n",
    "\n",
    "            scaler.step(optimizer)\n",
    "\n",
    "            scaler.update()\n",
    "\n",
    "        else:\n",
    "\n",
    "            outputs = model(images, return_features=True)\n",
    "            loss, batch_metrics = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            \n",
    "\n",
    "            if config.max_grad_norm:\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "\n",
    "            \n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if scheduler:\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        \n",
    "\n",
    "        # Update loss and metrics\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        for k, v in batch_metrics.items():\n",
    "\n",
    "            metrics[k] += v\n",
    "\n",
    "        \n",
    "\n",
    "        # Update progress bar with detailed information\n",
    "\n",
    "        pbar.set_postfix({\n",
    "\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "\n",
    "            'avg_loss': f'{total_loss / (batch_idx + 1):.4f}',\n",
    "\n",
    "            'lr': scheduler.get_last_lr()[0] if scheduler else optimizer.param_groups[0]['lr']\n",
    "\n",
    "        })\n",
    "\n",
    "    \n",
    "\n",
    "    # Normalize metrics over all batches\n",
    "\n",
    "    metrics = {k: v / len(train_loader) for k, v in metrics.items()}\n",
    "\n",
    "    return total_loss / len(train_loader), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdb23409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.444159Z",
     "iopub.status.busy": "2024-11-22T06:08:17.443915Z",
     "iopub.status.idle": "2024-11-22T06:08:17.448391Z",
     "shell.execute_reply": "2024-11-22T06:08:17.447613Z"
    },
    "papermill": {
     "duration": 0.015217,
     "end_time": "2024-11-22T06:08:17.450009",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.434792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_topk_accuracy(outputs, labels, k):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Computes the top-k accuracy for the given outputs and labels.\n",
    "\n",
    "    \n",
    "\n",
    "    Args:\n",
    "\n",
    "        outputs (torch.Tensor or dict): Model outputs, expected as a tensor.\n",
    "\n",
    "        labels (torch.Tensor): Ground truth labels.\n",
    "\n",
    "        k (int): The 'k' in top-k accuracy.\n",
    "\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "\n",
    "        float: Top-k accuracy as a percentage.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    outputs = outputs['student_logits']  # Update the key to match your dictionary structure\n",
    "\n",
    "    \n",
    "\n",
    "    _, top_k_preds = outputs.topk(k, dim=1)\n",
    "\n",
    "    top_k_correct = top_k_preds.eq(labels.view(-1, 1).expand_as(top_k_preds))\n",
    "\n",
    "    return top_k_correct.any(dim=1).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09b59a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.470332Z",
     "iopub.status.busy": "2024-11-22T06:08:17.470043Z",
     "iopub.status.idle": "2024-11-22T06:08:17.477035Z",
     "shell.execute_reply": "2024-11-22T06:08:17.476246Z"
    },
    "papermill": {
     "duration": 0.019528,
     "end_time": "2024-11-22T06:08:17.478766",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.459238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_epoch(model, val_loader, criterion, config):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    metrics = defaultdict(float)\n",
    "\n",
    "    \n",
    "\n",
    "    pbar = tqdm(val_loader, desc='Validating')\n",
    "\n",
    "    \n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(pbar):\n",
    "\n",
    "            images, labels = images.to(config.device), labels.to(config.device)\n",
    "\n",
    "            \n",
    "\n",
    "            # Forward pass\n",
    "\n",
    "            outputs = model(images, return_features=True)\n",
    "\n",
    "            loss, batch_metrics = criterion(outputs, labels)\n",
    "\n",
    "            \n",
    "\n",
    "            # Accumulate loss and metrics\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            metrics['top1_acc'] += compute_topk_accuracy(outputs, labels, 1)\n",
    "\n",
    "            metrics['top5_acc'] += compute_topk_accuracy(outputs, labels, 5)\n",
    "\n",
    "            metrics['top10_acc'] += compute_topk_accuracy(outputs, labels, 10)\n",
    "\n",
    "            \n",
    "\n",
    "            # Update progress bar\n",
    "\n",
    "            pbar.set_postfix({\n",
    "\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "\n",
    "                'avg_loss': f'{total_loss / (batch_idx + 1):.4f}'\n",
    "\n",
    "            })\n",
    "\n",
    "    \n",
    "\n",
    "    # Normalize metrics over all batches\n",
    "\n",
    "    metrics = {k: v / len(val_loader) for k, v in metrics.items()}\n",
    "\n",
    "    return total_loss / len(val_loader), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3c217aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.499757Z",
     "iopub.status.busy": "2024-11-22T06:08:17.499498Z",
     "iopub.status.idle": "2024-11-22T06:08:17.503245Z",
     "shell.execute_reply": "2024-11-22T06:08:17.502449Z"
    },
    "papermill": {
     "duration": 0.016306,
     "end_time": "2024-11-22T06:08:17.505109",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.488803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1813f5c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.526358Z",
     "iopub.status.busy": "2024-11-22T06:08:17.526079Z",
     "iopub.status.idle": "2024-11-22T06:08:17.530415Z",
     "shell.execute_reply": "2024-11-22T06:08:17.529551Z"
    },
    "papermill": {
     "duration": 0.017184,
     "end_time": "2024-11-22T06:08:17.532223",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.515039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = GoogleLandmarksDataset(train_df, class_name_to_idx=class_name_to_idx, transform=transforms_train)\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    num_workers=N_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95b4ef95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T06:08:17.553140Z",
     "iopub.status.busy": "2024-11-22T06:08:17.552862Z",
     "iopub.status.idle": "2024-11-22T09:32:52.953987Z",
     "shell.execute_reply": "2024-11-22T09:32:52.952556Z"
    },
    "papermill": {
     "duration": 12275.413888,
     "end_time": "2024-11-22T09:32:52.955965",
     "exception": false,
     "start_time": "2024-11-22T06:08:17.542077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bba83b013924f4f8e8a0561ff4713ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Starting Fold 0\n",
      "##############################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [17:15<00:00,  1.81it/s, loss=4.7409, avg_loss=4.8271, lr=9.96e-5]\n",
      "Validating: 100%|██████████| 235/235 [03:07<00:00,  1.25it/s, loss=4.5621, avg_loss=4.6689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 4.8271 | Val Loss: 4.6689 | Top1 Acc: 0.00 | Top5 Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [17:16<00:00,  1.81it/s, loss=4.7672, avg_loss=4.7792, lr=9.63e-5]\n",
      "Validating: 100%|██████████| 235/235 [03:06<00:00,  1.26it/s, loss=4.5387, avg_loss=4.5913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 4.7792 | Val Loss: 4.5913 | Top1 Acc: 0.01 | Top5 Acc: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [17:18<00:00,  1.81it/s, loss=4.6775, avg_loss=4.7123, lr=8.99e-5]\n",
      "Validating: 100%|██████████| 235/235 [03:07<00:00,  1.26it/s, loss=4.5266, avg_loss=4.5293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 4.7123 | Val Loss: 4.5293 | Top1 Acc: 0.02 | Top5 Acc: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [17:18<00:00,  1.81it/s, loss=4.5997, avg_loss=4.6600, lr=8.07e-5]\n",
      "Validating: 100%|██████████| 235/235 [03:06<00:00,  1.26it/s, loss=4.5145, avg_loss=4.4832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 4.6600 | Val Loss: 4.4832 | Top1 Acc: 0.03 | Top5 Acc: 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [17:18<00:00,  1.81it/s, loss=4.6457, avg_loss=4.6186, lr=6.94e-5]\n",
      "Validating: 100%|██████████| 235/235 [03:06<00:00,  1.26it/s, loss=4.5161, avg_loss=4.4521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 4.6186 | Val Loss: 4.4521 | Top1 Acc: 0.03 | Top5 Acc: 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [17:18<00:00,  1.81it/s, loss=4.5289, avg_loss=4.5859, lr=5.67e-5]\n",
      "Validating: 100%|██████████| 235/235 [03:07<00:00,  1.26it/s, loss=4.5066, avg_loss=4.4241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 4.5859 | Val Loss: 4.4241 | Top1 Acc: 0.04 | Top5 Acc: 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [17:17<00:00,  1.81it/s, loss=4.5123, avg_loss=4.5594, lr=4.36e-5]\n",
      "Validating: 100%|██████████| 235/235 [03:06<00:00,  1.26it/s, loss=4.4983, avg_loss=4.3987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 4.5594 | Val Loss: 4.3987 | Top1 Acc: 0.04 | Top5 Acc: 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [17:18<00:00,  1.81it/s, loss=4.5619, avg_loss=4.5370, lr=3.1e-5]\n",
      "Validating: 100%|██████████| 235/235 [03:06<00:00,  1.26it/s, loss=4.4992, avg_loss=4.3825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 4.5370 | Val Loss: 4.3825 | Top1 Acc: 0.05 | Top5 Acc: 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [17:18<00:00,  1.81it/s, loss=4.4993, avg_loss=4.5209, lr=1.96e-5]\n",
      "Validating: 100%|██████████| 235/235 [03:07<00:00,  1.26it/s, loss=4.5000, avg_loss=4.3691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 4.5209 | Val Loss: 4.3691 | Top1 Acc: 0.05 | Top5 Acc: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [17:18<00:00,  1.81it/s, loss=4.6523, avg_loss=4.5098, lr=1.04e-5]\n",
      "Validating: 100%|██████████| 235/235 [03:06<00:00,  1.26it/s, loss=4.4950, avg_loss=4.3660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 4.5098 | Val Loss: 4.3660 | Top1 Acc: 0.05 | Top5 Acc: 0.10\n",
      "Summary of Fold Metrics:\n",
      "{'fold': 0, 'train_loss': 4.509792407989502, 'val_loss': 4.365986122983568, 'top1_acc': 0.04860372340425532, 'top5_acc': 0.09833776595744681, 'top10_acc': 0.12591622340235303}\n"
     ]
    }
   ],
   "source": [
    "teacher_model = GoogleLandmarksModel(text_embeddings=text_embeddings, model_name=\"RN101\", device=device)\n",
    "teacher_model = teacher_model.float()\n",
    "\n",
    "checkpoint = torch.load('/kaggle/input/k/thangchu/training-clip-baseline-on-landmarks-index-set/clip_landmark_results/best_val_loss_model_fold-0.pth', weights_only = False)\n",
    "teacher_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "teacher_model.to(device)\n",
    "student_model = timm.create_model(\"resnet18\", pretrained=True, num_classes=N_CLASSES)\n",
    "student_model = student_model.float()\n",
    "\n",
    "\n",
    "# Initialize the improved distillation model\n",
    "\n",
    "distillation_model = CrossModalDistillationModel(\n",
    "\n",
    "    teacher_model=teacher_model,\n",
    "\n",
    "    student_model=student_model,\n",
    "\n",
    "    text_embeddings=text_embeddings.to(device),\n",
    "\n",
    "    projection_dim=512  # Same dimension as CLIP's feature space\n",
    "\n",
    ")\n",
    "\n",
    "distillation_model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer with weight decay\n",
    "\n",
    "optimizer = AdamW([\n",
    "\n",
    "    {'params': distillation_model.student.parameters(), 'lr': 1e-4},\n",
    "\n",
    "    {'params': distillation_model.projection_head.parameters(), 'lr': 1e-4}\n",
    "\n",
    "], weight_decay=0.01)\n",
    "\n",
    "\n",
    "\n",
    "# Scheduler with warmup\n",
    "\n",
    "num_training_steps = len(train_dl) * EPOCHS\n",
    "\n",
    "num_warmup_steps = min(1000, num_training_steps // 20)  # 10% of training steps or 1000, whichever is smaller\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "\n",
    "    optimizer, \n",
    "\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "\n",
    "    num_training_steps=num_training_steps\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Training loop with validation\n",
    "\n",
    "patience = EARLY_STOPPING_EPOCH\n",
    "\n",
    "patience_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "scaler = GradScaler() if USE_AMP else None\n",
    "\n",
    "\n",
    "\n",
    "sfk = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "training_folds = [0] \n",
    "\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(sfk.split(train_df, train_df.landmark_id.tolist())):\n",
    "    if fold not in training_folds:\n",
    "        continue\n",
    "\n",
    "    print(f\"{'#'*30}\\nStarting Fold {fold}\\n{'#'*30}\")\n",
    "\n",
    "    # Prepare datasets and dataloaders\n",
    "    df_train = train_df.iloc[trn_idx]\n",
    "    df_valid = train_df.iloc[val_idx]\n",
    "\n",
    "    train_ds = GoogleLandmarksDataset(df_train, class_name_to_idx=class_name_to_idx, transform=transforms_train)\n",
    "    valid_ds = GoogleLandmarksDataset(df_valid, class_name_to_idx=class_name_to_idx, transform=transforms_val)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS, drop_last=True, pin_memory=True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=N_WORKERS, drop_last=False, pin_memory=True)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_metrics = train_epoch(\n",
    "            model=distillation_model,\n",
    "            train_loader=train_dl,\n",
    "            criterion=EnhancedDistillationLoss(Config()),\n",
    "            optimizer=optimizer,\n",
    "            config=Config(),\n",
    "            scheduler=scheduler\n",
    "        )\n",
    "\n",
    "        val_loss, val_metrics = validate_epoch(\n",
    "            model=distillation_model,\n",
    "            val_loader=valid_dl,\n",
    "            criterion=EnhancedDistillationLoss(Config()),\n",
    "            config=Config()\n",
    "        )\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "              f\"Top1 Acc: {val_metrics['top1_acc']:.2f} | Top5 Acc: {val_metrics['top5_acc']:.2f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'fold': fold,\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': distillation_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "            }, f'{OUTPUT_DIR}/best_model_fold{fold}.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    fold_metrics.append({\n",
    "        'fold': fold,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'top1_acc': val_metrics['top1_acc'],\n",
    "        'top5_acc': val_metrics['top5_acc'],\n",
    "        'top10_acc': val_metrics['top10_acc'],\n",
    "    })\n",
    "\n",
    "# Print overall metrics\n",
    "print(\"Summary of Fold Metrics:\")\n",
    "for metric in fold_metrics:\n",
    "    print(metric)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5883095,
     "sourceId": 9635661,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5883097,
     "sourceId": 9635664,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5883577,
     "sourceId": 9636294,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5883578,
     "sourceId": 9636295,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5883713,
     "sourceId": 9636477,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5882766,
     "sourceId": 9720780,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5935937,
     "sourceId": 9828230,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6123513,
     "sourceId": 9956472,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 204129443,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 205653461,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 207864204,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12327.316024,
   "end_time": "2024-11-22T09:32:58.289316",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-22T06:07:30.973292",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b73b8c041664fc4bb2b6e8ec6782f31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "104d6ca0cdbf442bb1718fbf38e0dfcb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_36dff663d4bf465696cf48b271b60ef1",
       "placeholder": "​",
       "style": "IPY_MODEL_477b418769d2491b8edfec4283caf384",
       "value": " 46.8M/46.8M [00:00&lt;00:00, 86.4MB/s]"
      }
     },
     "36dff663d4bf465696cf48b271b60ef1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "477b418769d2491b8edfec4283caf384": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "575d1bba975349c689b2b976aa7f68fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "69270c349d924c87b0ae36b925d107ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7bba83b013924f4f8e8a0561ff4713ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f625ebd12eee48ca8d5e72e09933c861",
        "IPY_MODEL_decd0f97c9e34301a9de2b24aac72591",
        "IPY_MODEL_104d6ca0cdbf442bb1718fbf38e0dfcb"
       ],
       "layout": "IPY_MODEL_575d1bba975349c689b2b976aa7f68fc"
      }
     },
     "af6ec5a2f7e64b629d088cf9ec55a645": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bc407f276c7245a688b8f79b2a46d8db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "decd0f97c9e34301a9de2b24aac72591": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_69270c349d924c87b0ae36b925d107ed",
       "max": 46807446.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_af6ec5a2f7e64b629d088cf9ec55a645",
       "value": 46807446.0
      }
     },
     "f625ebd12eee48ca8d5e72e09933c861": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0b73b8c041664fc4bb2b6e8ec6782f31",
       "placeholder": "​",
       "style": "IPY_MODEL_bc407f276c7245a688b8f79b2a46d8db",
       "value": "model.safetensors: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
