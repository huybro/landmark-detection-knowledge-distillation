{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c4aa7f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:10.417942Z",
     "iopub.status.busy": "2024-11-20T16:28:10.417648Z",
     "iopub.status.idle": "2024-11-20T16:28:23.233670Z",
     "shell.execute_reply": "2024-11-20T16:28:23.232652Z"
    },
    "papermill": {
     "duration": 12.82367,
     "end_time": "2024-11-20T16:28:23.235861",
     "exception": false,
     "start_time": "2024-11-20T16:28:10.412191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\r\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-e35vhzjm\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-e35vhzjm\r\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting ftfy (from clip==1.0)\r\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (21.3)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2024.5.15)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.4)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.4.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.19.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->clip==1.0) (3.1.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (2024.6.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\r\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: clip\r\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=a1a863895ade09333a5017315d2cece11db283df649523f114222eb74ba501ac\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-x65w67dh/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\r\n",
      "Successfully built clip\r\n",
      "Installing collected packages: ftfy, clip\r\n",
      "Successfully installed clip-1.0 ftfy-6.3.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2965f346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:23.247582Z",
     "iopub.status.busy": "2024-11-20T16:28:23.246998Z",
     "iopub.status.idle": "2024-11-20T16:28:33.045177Z",
     "shell.execute_reply": "2024-11-20T16:28:33.044068Z"
    },
    "papermill": {
     "duration": 9.805818,
     "end_time": "2024-11-20T16:28:33.047006",
     "exception": false,
     "start_time": "2024-11-20T16:28:23.241188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.4.17)\r\n",
      "Collecting albumentations\r\n",
      "  Downloading albumentations-1.4.21-py3-none-any.whl.metadata (31 kB)\r\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.14.1)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.2)\r\n",
      "Requirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (2.9.2)\r\n",
      "Collecting albucore==0.0.20 (from albumentations)\r\n",
      "  Downloading albucore-0.0.20-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.2.0)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.10.0.84)\r\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.20->albumentations)\r\n",
      "  Downloading stringzilla-3.10.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting simsimd>=5.9.2 (from albucore==0.0.20->albumentations)\r\n",
      "  Downloading simsimd-6.1.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\r\n",
      "Downloading albumentations-1.4.21-py3-none-any.whl (227 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.9/227.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading albucore-0.0.20-py3-none-any.whl (12 kB)\r\n",
      "Downloading simsimd-6.1.1-cp310-cp310-manylinux_2_28_x86_64.whl (606 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.4/606.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading stringzilla-3.10.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (291 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.7/291.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: stringzilla, simsimd, albucore, albumentations\r\n",
      "  Attempting uninstall: albucore\r\n",
      "    Found existing installation: albucore 0.0.17\r\n",
      "    Uninstalling albucore-0.0.17:\r\n",
      "      Successfully uninstalled albucore-0.0.17\r\n",
      "  Attempting uninstall: albumentations\r\n",
      "    Found existing installation: albumentations 1.4.17\r\n",
      "    Uninstalling albumentations-1.4.17:\r\n",
      "      Successfully uninstalled albumentations-1.4.17\r\n",
      "Successfully installed albucore-0.0.20 albumentations-1.4.21 simsimd-6.1.1 stringzilla-3.10.10\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f33cdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:33.061138Z",
     "iopub.status.busy": "2024-11-20T16:28:33.060353Z",
     "iopub.status.idle": "2024-11-20T16:28:40.752281Z",
     "shell.execute_reply": "2024-11-20T16:28:40.751595Z"
    },
    "papermill": {
     "duration": 7.700503,
     "end_time": "2024-11-20T16:28:40.754350",
     "exception": false,
     "start_time": "2024-11-20T16:28:33.053847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import timm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "import albumentations as A\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import clip\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b38635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:40.767090Z",
     "iopub.status.busy": "2024-11-20T16:28:40.766638Z",
     "iopub.status.idle": "2024-11-20T16:28:40.771490Z",
     "shell.execute_reply": "2024-11-20T16:28:40.770777Z"
    },
    "papermill": {
     "duration": 0.012689,
     "end_time": "2024-11-20T16:28:40.772953",
     "exception": false,
     "start_time": "2024-11-20T16:28:40.760264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "DEBUG = False\n",
    "N_WORKERS = os.cpu_count() \n",
    "USE_AMP = False # can change True if using T4 or newer than Ampere\n",
    "SEED = 42\n",
    "CLIP_MODEL_NAME = \"RN101\"\n",
    "IMG_SIZE = [224, 224]\n",
    "AUG_PROB = 0.2\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "if DEBUG:\n",
    "    EPOCHS = 3\n",
    "GRAD_ACC = 1\n",
    "N_FOLDS = 5\n",
    "MAX_GRAD_NORM = None\n",
    "EARLY_STOPPING_EPOCH = 3\n",
    "OUTPUT_DIR = f'clip_landmark_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcec163e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:40.784891Z",
     "iopub.status.busy": "2024-11-20T16:28:40.784642Z",
     "iopub.status.idle": "2024-11-20T16:28:40.788114Z",
     "shell.execute_reply": "2024-11-20T16:28:40.787531Z"
    },
    "papermill": {
     "duration": 0.011125,
     "end_time": "2024-11-20T16:28:40.789587",
     "exception": false,
     "start_time": "2024-11-20T16:28:40.778462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f436a1ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:40.801810Z",
     "iopub.status.busy": "2024-11-20T16:28:40.801135Z",
     "iopub.status.idle": "2024-11-20T16:28:41.691286Z",
     "shell.execute_reply": "2024-11-20T16:28:41.690333Z"
    },
    "papermill": {
     "duration": 0.897995,
     "end_time": "2024-11-20T16:28:41.693128",
     "exception": false,
     "start_time": "2024-11-20T16:28:40.795133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>category</th>\n",
       "      <th>supercategory</th>\n",
       "      <th>hierarchical_label</th>\n",
       "      <th>natural_or_human_made</th>\n",
       "      <th>cleaned_supercategory</th>\n",
       "      <th>image_path</th>\n",
       "      <th>landmark_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73792c1235ff2625</td>\n",
       "      <td>33618</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Don...</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>human-made</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p3...</td>\n",
       "      <td>Dona i Ocell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a3751bcb2740c891</td>\n",
       "      <td>33618</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Don...</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>human-made</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p4...</td>\n",
       "      <td>Dona i Ocell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2f32b63b86113c22</td>\n",
       "      <td>33618</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Don...</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>human-made</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p1...</td>\n",
       "      <td>Dona i Ocell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>657c10997e4f399c</td>\n",
       "      <td>33618</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Don...</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>human-made</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p2...</td>\n",
       "      <td>Dona i Ocell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>029ba12e494a33ff</td>\n",
       "      <td>33618</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Category:Don...</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>human-made</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>/kaggle/input/google-landmarks-v2-index-set-p1...</td>\n",
       "      <td>Dona i Ocell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  landmark_id  \\\n",
       "0  73792c1235ff2625        33618   \n",
       "1  a3751bcb2740c891        33618   \n",
       "2  2f32b63b86113c22        33618   \n",
       "3  657c10997e4f399c        33618   \n",
       "4  029ba12e494a33ff        33618   \n",
       "\n",
       "                                            category supercategory  \\\n",
       "0  http://commons.wikimedia.org/wiki/Category:Don...     sculpture   \n",
       "1  http://commons.wikimedia.org/wiki/Category:Don...     sculpture   \n",
       "2  http://commons.wikimedia.org/wiki/Category:Don...     sculpture   \n",
       "3  http://commons.wikimedia.org/wiki/Category:Don...     sculpture   \n",
       "4  http://commons.wikimedia.org/wiki/Category:Don...     sculpture   \n",
       "\n",
       "  hierarchical_label natural_or_human_made cleaned_supercategory  \\\n",
       "0          sculpture            human-made             sculpture   \n",
       "1          sculpture            human-made             sculpture   \n",
       "2          sculpture            human-made             sculpture   \n",
       "3          sculpture            human-made             sculpture   \n",
       "4          sculpture            human-made             sculpture   \n",
       "\n",
       "                                          image_path landmark_name  \n",
       "0  /kaggle/input/google-landmarks-v2-index-set-p3...  Dona i Ocell  \n",
       "1  /kaggle/input/google-landmarks-v2-index-set-p4...  Dona i Ocell  \n",
       "2  /kaggle/input/google-landmarks-v2-index-set-p1...  Dona i Ocell  \n",
       "3  /kaggle/input/google-landmarks-v2-index-set-p2...  Dona i Ocell  \n",
       "4  /kaggle/input/google-landmarks-v2-index-set-p1...  Dona i Ocell  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/google-landmarks-v2-index-subset-metadata/cleaned_landmark_index_subset_150k_v2.csv\")\n",
    "if DEBUG:\n",
    "    # Reduce to 1000 samples for quick debugging\n",
    "    train_df = train_df.sample(1000, random_state=42).reset_index(drop=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12199a52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:41.706002Z",
     "iopub.status.busy": "2024-11-20T16:28:41.705659Z",
     "iopub.status.idle": "2024-11-20T16:28:41.730792Z",
     "shell.execute_reply": "2024-11-20T16:28:41.729994Z"
    },
    "papermill": {
     "duration": 0.03337,
     "end_time": "2024-11-20T16:28:41.732490",
     "exception": false,
     "start_time": "2024-11-20T16:28:41.699120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_CLASSES = train_df.landmark_name.nunique()\n",
    "class_names = train_df.landmark_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e64a5e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:41.745358Z",
     "iopub.status.busy": "2024-11-20T16:28:41.745082Z",
     "iopub.status.idle": "2024-11-20T16:28:58.434879Z",
     "shell.execute_reply": "2024-11-20T16:28:58.433967Z"
    },
    "papermill": {
     "duration": 16.698455,
     "end_time": "2024-11-20T16:28:58.436642",
     "exception": false,
     "start_time": "2024-11-20T16:28:41.738187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 278M/278M [00:11<00:00, 24.5MiB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'text_prompts = [f\"A photo of {name} or its part\" for name in class_names]\\ntext_tokens = clip.tokenize(text_prompts).to(embedding_device)\\n\\n# Compute text embeddings\\nwith torch.no_grad():\\n    text_embeddings = model.encode_text(text_tokens)\\ntext_embeddings = text_embeddings / text_embeddings.norm(dim=-1, keepdim=True)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CLIP model\n",
    "embedding_device = \"cpu\"\n",
    "model, _ = clip.load(CLIP_MODEL_NAME, device=embedding_device)\n",
    "\n",
    "# Define class names and tokenize\n",
    "\"\"\"text_prompts = [f\"A photo of {name} or its part\" for name in class_names]\n",
    "text_tokens = clip.tokenize(text_prompts).to(embedding_device)\n",
    "\n",
    "# Compute text embeddings\n",
    "with torch.no_grad():\n",
    "    text_embeddings = model.encode_text(text_tokens)\n",
    "text_embeddings = text_embeddings / text_embeddings.norm(dim=-1, keepdim=True)\"\"\"  # Normalize for cosine similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85bef93a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:58.456451Z",
     "iopub.status.busy": "2024-11-20T16:28:58.456165Z",
     "iopub.status.idle": "2024-11-20T16:28:58.719091Z",
     "shell.execute_reply": "2024-11-20T16:28:58.718412Z"
    },
    "papermill": {
     "duration": 0.27478,
     "end_time": "2024-11-20T16:28:58.720976",
     "exception": false,
     "start_time": "2024-11-20T16:28:58.446196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_embeddings = torch.load(\"/kaggle/input/text_embeddings/pytorch/default/1/text_embeddings.pt\", weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b88a88d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:58.741561Z",
     "iopub.status.busy": "2024-11-20T16:28:58.740890Z",
     "iopub.status.idle": "2024-11-20T16:28:58.746753Z",
     "shell.execute_reply": "2024-11-20T16:28:58.745994Z"
    },
    "papermill": {
     "duration": 0.017677,
     "end_time": "2024-11-20T16:28:58.748409",
     "exception": false,
     "start_time": "2024-11-20T16:28:58.730732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_name_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "idx_to_class_name = {idx: class_name for class_name, idx in class_name_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff2f0f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:58.767696Z",
     "iopub.status.busy": "2024-11-20T16:28:58.767448Z",
     "iopub.status.idle": "2024-11-20T16:28:58.785750Z",
     "shell.execute_reply": "2024-11-20T16:28:58.784788Z"
    },
    "papermill": {
     "duration": 0.029179,
     "end_time": "2024-11-20T16:28:58.787259",
     "exception": false,
     "start_time": "2024-11-20T16:28:58.758080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "transforms_train = A.Compose([\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=AUG_PROB),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=5),\n",
    "        A.MedianBlur(blur_limit=5),\n",
    "        A.GaussianBlur(blur_limit=5),\n",
    "        A.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "    ], p=AUG_PROB),\n",
    "\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(distort_limit=1.0),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "        A.ElasticTransform(alpha=3),\n",
    "    ], p=AUG_PROB),\n",
    "\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=AUG_PROB),\n",
    "    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=1, min_height=8, min_width=8, p=AUG_PROB),    \n",
    "    A.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], \n",
    "                         std=[0.26862954, 0.26130258, 0.27577711])\n",
    "])\n",
    "\n",
    "transforms_val = A.Compose([\n",
    "    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "    A.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], \n",
    "                         std=[0.26862954, 0.26130258, 0.27577711])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "526ecc53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:58.806049Z",
     "iopub.status.busy": "2024-11-20T16:28:58.805770Z",
     "iopub.status.idle": "2024-11-20T16:28:58.811409Z",
     "shell.execute_reply": "2024-11-20T16:28:58.810793Z"
    },
    "papermill": {
     "duration": 0.016864,
     "end_time": "2024-11-20T16:28:58.812922",
     "exception": false,
     "start_time": "2024-11-20T16:28:58.796058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GoogleLandmarksDataset(Dataset):\n",
    "    def __init__(self, df, class_name_to_idx, transform=None):\n",
    "        self.df = df\n",
    "        self.class_name_to_idx = class_name_to_idx  # Maps class name to index\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = self.df.iloc[idx]\n",
    "        class_name = t['landmark_name']\n",
    "        class_name_idx = self.class_name_to_idx[class_name]\n",
    "        \n",
    "        p = f'{t[\"image_path\"]}'\n",
    "        img = Image.open(p)\n",
    "        img = np.array(img)\n",
    "            \n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            img = self.transform(image=np.array(img))['image']\n",
    "        \n",
    "        # Convert image to tensor if needed\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "        \n",
    "        return img, class_name_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00a56d77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:58.831707Z",
     "iopub.status.busy": "2024-11-20T16:28:58.831482Z",
     "iopub.status.idle": "2024-11-20T16:28:58.839673Z",
     "shell.execute_reply": "2024-11-20T16:28:58.838903Z"
    },
    "papermill": {
     "duration": 0.019412,
     "end_time": "2024-11-20T16:28:58.841220",
     "exception": false,
     "start_time": "2024-11-20T16:28:58.821808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CrossModalDistillationModel(nn.Module):\n",
    "    def __init__(self, teacher_model, student_model, text_embeddings, projection_dim=512):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher_model\n",
    "        self.student = student_model\n",
    "        self.text_embeddings = text_embeddings\n",
    "        \n",
    "        # Freeze teacher\n",
    "        for param in self.teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Get input features dimension\n",
    "        in_features = student_model.get_classifier().in_features\n",
    "        \n",
    "        # Single projection head for student\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, projection_dim),\n",
    "            nn.BatchNorm1d(projection_dim)  # Added BatchNorm for stable training\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(in_features, student_model.get_classifier().out_features)\n",
    "        \n",
    "        # Temperature parameter\n",
    "        self.temperature = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "        \n",
    "    def forward(self, images, return_features=True):\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        # Teacher forward pass\n",
    "        with torch.no_grad():\n",
    "            teacher_features = self.teacher.encode_image(images)\n",
    "            teacher_features = F.normalize(teacher_features, dim=-1)\n",
    "            teacher_features = teacher_features.float()\n",
    "            self.text_embeddings = self.text_embeddings.float()\n",
    "            teacher_logits = torch.matmul(teacher_features, self.text_embeddings.t())\n",
    "            teacher_logits = teacher_logits * self.temperature.exp()\n",
    "\n",
    "        # Student forward pass\n",
    "        student_features = self.student.forward_features(images)\n",
    "        student_features = F.adaptive_avg_pool2d(student_features, (1, 1))\n",
    "        student_features = student_features.view(batch_size, -1)\n",
    "\n",
    "        # Project student features\n",
    "        student_projected = self.projection_head(student_features)\n",
    "        student_projected = F.normalize(student_projected, dim=-1)\n",
    "\n",
    "        # Get classification logits\n",
    "        student_logits = self.classifier(student_features)\n",
    "\n",
    "        if return_features:\n",
    "            return {\n",
    "                'teacher_logits': teacher_logits,\n",
    "                'student_logits': student_logits,\n",
    "                'teacher_features': teacher_features,\n",
    "                'student_projected': student_projected,\n",
    "                'student_features': student_features\n",
    "            }\n",
    "        \n",
    "        return student_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "107d0fa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:58.860063Z",
     "iopub.status.busy": "2024-11-20T16:28:58.859809Z",
     "iopub.status.idle": "2024-11-20T16:28:58.864259Z",
     "shell.execute_reply": "2024-11-20T16:28:58.863483Z"
    },
    "papermill": {
     "duration": 0.015655,
     "end_time": "2024-11-20T16:28:58.865878",
     "exception": false,
     "start_time": "2024-11-20T16:28:58.850223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.alpha = 0.2\n",
    "        self.beta = 0.2\n",
    "        self.gamma = 0.5\n",
    "        self.temperature = 2.0\n",
    "        self.device = device\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.n_workers = N_WORKERS\n",
    "        self.max_grad_norm = MAX_GRAD_NORM\n",
    "        self.log_interval = 100\n",
    "        self.use_amp = False\n",
    "        self.use_wandb = False  # Set to True if using wandb\n",
    "        self.warmup_steps = 100\n",
    "        self.gradient_accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "316c2459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:58.884402Z",
     "iopub.status.busy": "2024-11-20T16:28:58.884159Z",
     "iopub.status.idle": "2024-11-20T16:28:58.891990Z",
     "shell.execute_reply": "2024-11-20T16:28:58.891222Z"
    },
    "papermill": {
     "duration": 0.018794,
     "end_time": "2024-11-20T16:28:58.893507",
     "exception": false,
     "start_time": "2024-11-20T16:28:58.874713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class EnhancedDistillationLoss(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.alpha = config.alpha  # KD loss weight\n",
    "        self.beta = config.beta    # Feature alignment weight\n",
    "        self.gamma = config.gamma  # CE loss weight\n",
    "        self.T = config.temperature\n",
    "        self.contrastive_weight = 0.1  # Weight for contrastive loss\n",
    "        \n",
    "    def contrastive_loss(self, features, labels):\n",
    "        # Implement contrastive loss between positive pairs\n",
    "        similarity = torch.matmul(features, features.t())\n",
    "        mask = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        \n",
    "        # Temperature-scaled similarities\n",
    "        similarity = similarity / self.T\n",
    "        \n",
    "        # Positive and negative pairs\n",
    "        exp_sim = torch.exp(similarity)\n",
    "        pos_sim = exp_sim * mask\n",
    "        neg_sim = exp_sim * (1 - mask)\n",
    "        \n",
    "        loss = -torch.log(\n",
    "            pos_sim.sum(1) / (pos_sim.sum(1) + neg_sim.sum(1))\n",
    "        ).mean()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        teacher_logits = outputs['teacher_logits']\n",
    "        student_logits = outputs['student_logits']\n",
    "        teacher_features = outputs['teacher_features']\n",
    "        student_projected = outputs['student_projected']\n",
    "        \n",
    "        # 1. Knowledge Distillation Loss\n",
    "        kd_loss = F.kl_div(\n",
    "            F.log_softmax(student_logits / self.T, dim=1),\n",
    "            F.softmax(teacher_logits / self.T, dim=1),\n",
    "            reduction=\"batchmean\"\n",
    "        ) * (self.T ** 2)\n",
    "        \n",
    "        # 2. Feature Alignment Loss\n",
    "        feature_loss = F.mse_loss(student_projected, teacher_features)\n",
    "        \n",
    "        # 3. Cross Entropy Loss\n",
    "        ce_loss = F.cross_entropy(student_logits, labels)\n",
    "        \n",
    "        # 4. Contrastive Loss\n",
    "        cont_loss = self.contrastive_loss(student_projected, labels)\n",
    "        \n",
    "        total_loss = (\n",
    "            self.alpha * kd_loss +\n",
    "            self.beta * feature_loss +\n",
    "            self.gamma * ce_loss +\n",
    "            self.contrastive_weight * cont_loss\n",
    "        )\n",
    "        \n",
    "        return total_loss, {\n",
    "            'kd_loss': kd_loss.item(),\n",
    "            'feature_loss': feature_loss.item(),\n",
    "            'ce_loss': ce_loss.item(),\n",
    "            'cont_loss': cont_loss.item()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b966504b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:58.912274Z",
     "iopub.status.busy": "2024-11-20T16:28:58.912035Z",
     "iopub.status.idle": "2024-11-20T16:28:58.920870Z",
     "shell.execute_reply": "2024-11-20T16:28:58.920091Z"
    },
    "papermill": {
     "duration": 0.020004,
     "end_time": "2024-11-20T16:28:58.922346",
     "exception": false,
     "start_time": "2024-11-20T16:28:58.902342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, config, scheduler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    metrics = defaultdict(float)  # Tracks additional metrics\n",
    "    scaler = GradScaler() if config.use_amp else None\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images, labels = images.to(config.device), labels.to(config.device)\n",
    "        \n",
    "        # Mixed precision training\n",
    "        if config.use_amp:\n",
    "            with autocast():\n",
    "                outputs = model(images, return_features=True)\n",
    "                loss, batch_metrics = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if config.max_grad_norm:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images, return_features=True)\n",
    "            loss, batch_metrics = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            if config.max_grad_norm:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Update loss and metrics\n",
    "        total_loss += loss.item()\n",
    "        for k, v in batch_metrics.items():\n",
    "            metrics[k] += v\n",
    "        \n",
    "        # Update progress bar with detailed information\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'avg_loss': f'{total_loss / (batch_idx + 1):.4f}',\n",
    "            'lr': scheduler.get_last_lr()[0] if scheduler else optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "    \n",
    "    # Normalize metrics over all batches\n",
    "    metrics = {k: v / len(train_loader) for k, v in metrics.items()}\n",
    "    return total_loss / len(train_loader), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d38d362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:58.940941Z",
     "iopub.status.busy": "2024-11-20T16:28:58.940681Z",
     "iopub.status.idle": "2024-11-20T16:28:58.945132Z",
     "shell.execute_reply": "2024-11-20T16:28:58.944366Z"
    },
    "papermill": {
     "duration": 0.015393,
     "end_time": "2024-11-20T16:28:58.946635",
     "exception": false,
     "start_time": "2024-11-20T16:28:58.931242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_topk_accuracy(outputs, labels, k):\n",
    "    \"\"\"\n",
    "    Computes the top-k accuracy for the given outputs and labels.\n",
    "    \n",
    "    Args:\n",
    "        outputs (torch.Tensor or dict): Model outputs, expected as a tensor.\n",
    "        labels (torch.Tensor): Ground truth labels.\n",
    "        k (int): The 'k' in top-k accuracy.\n",
    "    \n",
    "    Returns:\n",
    "        float: Top-k accuracy as a percentage.\n",
    "    \"\"\"\n",
    "    if isinstance(outputs, dict):\n",
    "        outputs = outputs['student_logits']  # Update the key to match your dictionary structure\n",
    "    \n",
    "    _, top_k_preds = outputs.topk(k, dim=1)\n",
    "    top_k_correct = top_k_preds.eq(labels.view(-1, 1).expand_as(top_k_preds))\n",
    "    return top_k_correct.any(dim=1).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1721167b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:58.965367Z",
     "iopub.status.busy": "2024-11-20T16:28:58.965152Z",
     "iopub.status.idle": "2024-11-20T16:28:58.971219Z",
     "shell.execute_reply": "2024-11-20T16:28:58.970447Z"
    },
    "papermill": {
     "duration": 0.017196,
     "end_time": "2024-11-20T16:28:58.972721",
     "exception": false,
     "start_time": "2024-11-20T16:28:58.955525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_epoch(model, val_loader, criterion, config):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    metrics = defaultdict(float)\n",
    "    \n",
    "    pbar = tqdm(val_loader, desc='Validating')\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch_idx, (images, labels) in enumerate(pbar):\n",
    "            images, labels = images.to(config.device), labels.to(config.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images, return_features=True)\n",
    "            loss, batch_metrics = criterion(outputs, labels)\n",
    "            \n",
    "            # Accumulate loss and metrics\n",
    "            total_loss += loss.item()\n",
    "            metrics['top1_acc'] += compute_topk_accuracy(outputs, labels, 1)\n",
    "            metrics['top5_acc'] += compute_topk_accuracy(outputs, labels, 5)\n",
    "            metrics['top10_acc'] += compute_topk_accuracy(outputs, labels, 10)\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'avg_loss': f'{total_loss / (batch_idx + 1):.4f}'\n",
    "            })\n",
    "    \n",
    "    # Normalize metrics over all batches\n",
    "    metrics = {k: v / len(val_loader) for k, v in metrics.items()}\n",
    "    return total_loss / len(val_loader), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa8708ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:58.991369Z",
     "iopub.status.busy": "2024-11-20T16:28:58.991130Z",
     "iopub.status.idle": "2024-11-20T16:28:58.994505Z",
     "shell.execute_reply": "2024-11-20T16:28:58.993732Z"
    },
    "papermill": {
     "duration": 0.014394,
     "end_time": "2024-11-20T16:28:58.996045",
     "exception": false,
     "start_time": "2024-11-20T16:28:58.981651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85499662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:59.014887Z",
     "iopub.status.busy": "2024-11-20T16:28:59.014614Z",
     "iopub.status.idle": "2024-11-20T16:28:59.018602Z",
     "shell.execute_reply": "2024-11-20T16:28:59.017842Z"
    },
    "papermill": {
     "duration": 0.014897,
     "end_time": "2024-11-20T16:28:59.020105",
     "exception": false,
     "start_time": "2024-11-20T16:28:59.005208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = GoogleLandmarksDataset(train_df, class_name_to_idx=class_name_to_idx, transform=transforms_train)\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    num_workers=N_WORKERS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beb8e50c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:28:59.038937Z",
     "iopub.status.busy": "2024-11-20T16:28:59.038437Z",
     "iopub.status.idle": "2024-11-20T18:59:29.877665Z",
     "shell.execute_reply": "2024-11-20T18:59:29.876282Z"
    },
    "papermill": {
     "duration": 9030.850926,
     "end_time": "2024-11-20T18:59:29.879748",
     "exception": false,
     "start_time": "2024-11-20T16:28:59.028822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fad35f7dd544099faeeee007bf0512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Starting Fold 0\n",
      "##############################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [15:05<00:00,  2.07it/s, loss=4.7532, avg_loss=4.8048, lr=9.96e-5]\n",
      "Validating: 100%|██████████| 235/235 [02:17<00:00,  1.71it/s, loss=4.7190, avg_loss=4.5856]\n",
      "Training: 100%|██████████| 1875/1875 [12:48<00:00,  2.44it/s, loss=4.5897, avg_loss=4.6553, lr=9.63e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:42<00:00,  2.30it/s, loss=4.6813, avg_loss=4.5166]\n",
      "Training: 100%|██████████| 1875/1875 [13:00<00:00,  2.40it/s, loss=4.7411, avg_loss=4.5980, lr=8.99e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:41<00:00,  2.31it/s, loss=4.6288, avg_loss=4.4733]\n",
      "Training: 100%|██████████| 1875/1875 [12:55<00:00,  2.42it/s, loss=4.4860, avg_loss=4.5566, lr=8.07e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:41<00:00,  2.31it/s, loss=4.5736, avg_loss=4.4371]\n",
      "Training: 100%|██████████| 1875/1875 [13:00<00:00,  2.40it/s, loss=4.3363, avg_loss=4.5204, lr=6.94e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:42<00:00,  2.30it/s, loss=4.5500, avg_loss=4.4094]\n",
      "Training: 100%|██████████| 1875/1875 [13:12<00:00,  2.37it/s, loss=4.3127, avg_loss=4.4913, lr=5.68e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:42<00:00,  2.30it/s, loss=4.5298, avg_loss=4.3853]\n",
      "Training: 100%|██████████| 1875/1875 [13:10<00:00,  2.37it/s, loss=4.1613, avg_loss=4.4650, lr=4.37e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:41<00:00,  2.31it/s, loss=4.5085, avg_loss=4.3646]\n",
      "Training: 100%|██████████| 1875/1875 [13:05<00:00,  2.39it/s, loss=4.1658, avg_loss=4.4438, lr=3.1e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:42<00:00,  2.30it/s, loss=4.4884, avg_loss=4.3525]\n",
      "Training: 100%|██████████| 1875/1875 [13:08<00:00,  2.38it/s, loss=4.4157, avg_loss=4.4296, lr=1.97e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:42<00:00,  2.30it/s, loss=4.4719, avg_loss=4.3413]\n",
      "Training: 100%|██████████| 1875/1875 [13:04<00:00,  2.39it/s, loss=4.4395, avg_loss=4.4203, lr=1.04e-5]\n",
      "Validating: 100%|██████████| 235/235 [01:47<00:00,  2.19it/s, loss=4.4525, avg_loss=4.3389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fold': 0, 'train_loss': 4.420293859227498, 'val_loss': 4.338883466543035, 'top1_acc': 0.09564494680851064, 'top5_acc': 0.14148936170212767, 'top10_acc': 0.1540226063829787}\n"
     ]
    }
   ],
   "source": [
    "teacher_model, preprocess = clip.load(CLIP_MODEL_NAME, device=device)\n",
    "student_model = timm.create_model(\"resnet18\", pretrained=True, num_classes=N_CLASSES)\n",
    "\n",
    "# Initialize the improved distillation model\n",
    "distillation_model = CrossModalDistillationModel(\n",
    "    teacher_model=teacher_model,\n",
    "    student_model=student_model,\n",
    "    text_embeddings=text_embeddings.to(device),\n",
    "    projection_dim=512  # Same dimension as CLIP's feature space\n",
    ")\n",
    "distillation_model.to(device)\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = AdamW([\n",
    "    {'params': distillation_model.student.parameters(), 'lr': 1e-4},\n",
    "    {'params': distillation_model.projection_head.parameters(), 'lr': 1e-4}\n",
    "], weight_decay=0.01)\n",
    "\n",
    "# Scheduler with warmup\n",
    "num_training_steps = len(train_dl) * EPOCHS\n",
    "num_warmup_steps = min(1000, num_training_steps // 20)  # 10% of training steps or 1000, whichever is smaller\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Training loop with validation\n",
    "patience = EARLY_STOPPING_EPOCH\n",
    "patience_counter = 0\n",
    "\n",
    "scaler = GradScaler() if USE_AMP else None\n",
    "\n",
    "sfk = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "training_folds = [0] \n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(sfk.split(train_df, train_df.landmark_id.tolist())):\n",
    "    if fold not in training_folds:\n",
    "        continue\n",
    "\n",
    "    print('#'*30)\n",
    "    print(f'Starting Fold {fold}')\n",
    "    print('#'*30)\n",
    "\n",
    "    df_train = train_df.iloc[trn_idx]\n",
    "    df_valid = train_df.iloc[val_idx]\n",
    "\n",
    "    # Initialize Datasets and DataLoaders\n",
    "    train_ds = GoogleLandmarksDataset(df_train, class_name_to_idx=class_name_to_idx, transform=transforms_train)\n",
    "    valid_ds = GoogleLandmarksDataset(df_valid, class_name_to_idx=class_name_to_idx, transform=transforms_val)\n",
    "    \n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, drop_last=True, num_workers=N_WORKERS)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE*2, shuffle=False, pin_memory=True, drop_last=False, num_workers=N_WORKERS)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_metrics = train_epoch(\n",
    "            model=distillation_model,\n",
    "            train_loader=train_dl,\n",
    "            criterion=EnhancedDistillationLoss(Config()),\n",
    "            optimizer=optimizer,\n",
    "            config=Config(),\n",
    "            scheduler=scheduler\n",
    "        )\n",
    "\n",
    "        val_loss, val_metrics = validate_epoch(\n",
    "            model=distillation_model,\n",
    "            val_loader=valid_dl,\n",
    "            criterion=EnhancedDistillationLoss(Config()),\n",
    "            config=Config()\n",
    "        )\n",
    "\n",
    "        # Save Best Model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'fold': fold,\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': distillation_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "            }, f'{OUTPUT_DIR}/best_model_fold{fold}.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "                break\n",
    "    \n",
    "    fold_metrics.append({\n",
    "        'fold': fold,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'top1_acc': val_metrics['top1_acc'],\n",
    "        'top5_acc': val_metrics['top5_acc'],\n",
    "        'top10_acc': val_metrics['top10_acc'],\n",
    "    })\n",
    "\n",
    "# Print Summary\n",
    "for metric in fold_metrics:\n",
    "    print(metric)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5883095,
     "sourceId": 9635661,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5883097,
     "sourceId": 9635664,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5883577,
     "sourceId": 9636294,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5883578,
     "sourceId": 9636295,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5883713,
     "sourceId": 9636477,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5882766,
     "sourceId": 9720780,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5935937,
     "sourceId": 9828230,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6123513,
     "sourceId": 9956472,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 204129443,
     "sourceType": "kernelVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 169221,
     "modelInstanceId": 146691,
     "sourceId": 172332,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9086.560397,
   "end_time": "2024-11-20T18:59:34.721112",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-20T16:28:08.160715",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "09cb05cd12a247ceac375a034ff1ef36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1ea7f5be3bcd4c4a900a0b9b114e9592": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "422dd529e45b479da5dccc8fd848ccc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fd31648fb4a9423b83dad22dba7e43cd",
       "max": 46807446.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_09cb05cd12a247ceac375a034ff1ef36",
       "value": 46807446.0
      }
     },
     "54fad35f7dd544099faeeee007bf0512": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_55d21f3c1d0647958dba28274e5825fd",
        "IPY_MODEL_422dd529e45b479da5dccc8fd848ccc2",
        "IPY_MODEL_fb3a704604bf4d80a44127c855d01789"
       ],
       "layout": "IPY_MODEL_f9c84bb5d3bc4684988d65f3656346f3"
      }
     },
     "55d21f3c1d0647958dba28274e5825fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a77cb9de3a904625a9c257330c42811f",
       "placeholder": "​",
       "style": "IPY_MODEL_b2e1da983a50484b9856fc2a94a4767c",
       "value": "model.safetensors: 100%"
      }
     },
     "a77cb9de3a904625a9c257330c42811f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2e1da983a50484b9856fc2a94a4767c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f512efd9eced40668159faad0a245ab8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9c84bb5d3bc4684988d65f3656346f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb3a704604bf4d80a44127c855d01789": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f512efd9eced40668159faad0a245ab8",
       "placeholder": "​",
       "style": "IPY_MODEL_1ea7f5be3bcd4c4a900a0b9b114e9592",
       "value": " 46.8M/46.8M [00:00&lt;00:00, 98.1MB/s]"
      }
     },
     "fd31648fb4a9423b83dad22dba7e43cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
